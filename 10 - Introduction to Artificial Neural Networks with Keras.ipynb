{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\clmen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# set the variables\n",
    "x = tf.Variable(3,name = \"x\")\n",
    "y = tf.Variable(4, name='y')\n",
    "\n",
    "# create the computation graph\n",
    "f = x*x*y+y+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# create session\n",
    "sess = tf.Session()\n",
    "\n",
    "# initialize variables\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    \n",
    "    result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # prepare an init node\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any node created is automaticaly added to the default graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # create x2 on the default graph (which is temporarilly graph)\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "print(x2.graph is graph)\n",
    "\n",
    "print(x2.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "# run twice x and w.\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) # 10\n",
    "    print(z.eval()) # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# run onl once w and x.\n",
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y,z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full,y_train_full), (X_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "\n",
    "def plot_image(img):\n",
    "    plt.imshow(img,cmap='binary')\n",
    "    plt.axis(False)\n",
    "plot_image(X_train[0])\n",
    "plt.show()\n",
    "\n",
    "print(class_names[y_train[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential API\n",
    "#### MLP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential() # sequential API\n",
    "\n",
    "# convert input into 1D array = preprocessing. First layer => specify input_shape\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "# Fully connected / Dense layer, specify nb units and activation functions.\n",
    "model.add(keras.layers.Dense(300,activation='relu'))\n",
    "model.add(keras.layers.Dense(100,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x228d99425c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x228d99427f0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x228d9942c18>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x228d9942f28>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n",
      "dense\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1].name)\n",
    "print(model.get_layer('dense').name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sparse_categorical_crossentropy because we have y sparse, cad y = nb between 0 and 9.\n",
    "# It is not one-hot encoded vec.\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', # or keras.losses.sparse_categorical_crossentropy\n",
    "             optimizer='sgd', # or keras.optimizers.SGD()\n",
    "             metrics=['accuracy']) # or [keras.metrics.sparse_categorical_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.7206 - acc: 0.7634 - val_loss: 0.5249 - val_acc: 0.8190\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.4917 - acc: 0.8286 - val_loss: 0.4844 - val_acc: 0.8314\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.4483 - acc: 0.8423 - val_loss: 0.4544 - val_acc: 0.8404\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.4219 - acc: 0.8509 - val_loss: 0.4347 - val_acc: 0.8470\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 6s 107us/sample - loss: 0.4008 - acc: 0.8587 - val_loss: 0.3904 - val_acc: 0.8664\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.3856 - acc: 0.8654 - val_loss: 0.3787 - val_acc: 0.8716\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.3717 - acc: 0.8693 - val_loss: 0.3707 - val_acc: 0.8706\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.3589 - acc: 0.8732 - val_loss: 0.3698 - val_acc: 0.8726\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.3502 - acc: 0.8763 - val_loss: 0.3535 - val_acc: 0.8772\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.3397 - acc: 0.8802 - val_loss: 0.3705 - val_acc: 0.8684\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.3326 - acc: 0.8820 - val_loss: 0.3450 - val_acc: 0.8754\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.3226 - acc: 0.8854 - val_loss: 0.3361 - val_acc: 0.8826\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.3154 - acc: 0.8867 - val_loss: 0.3470 - val_acc: 0.8756\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.3083 - acc: 0.8899 - val_loss: 0.3293 - val_acc: 0.8840\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.3016 - acc: 0.8919 - val_loss: 0.3597 - val_acc: 0.8732\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.2947 - acc: 0.8947 - val_loss: 0.3285 - val_acc: 0.8842\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.2901 - acc: 0.8954 - val_loss: 0.3405 - val_acc: 0.8766\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.2847 - acc: 0.8986 - val_loss: 0.3244 - val_acc: 0.8866\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 8s 138us/sample - loss: 0.2785 - acc: 0.8997 - val_loss: 0.3407 - val_acc: 0.8792\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.2729 - acc: 0.9016 - val_loss: 0.3204 - val_acc: 0.8848\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.2688 - acc: 0.9027 - val_loss: 0.3223 - val_acc: 0.8836\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 8s 139us/sample - loss: 0.2643 - acc: 0.9048 - val_loss: 0.3100 - val_acc: 0.8882\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.2589 - acc: 0.9071 - val_loss: 0.3014 - val_acc: 0.8938\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.2548 - acc: 0.9082 - val_loss: 0.3136 - val_acc: 0.8874\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 8s 138us/sample - loss: 0.2509 - acc: 0.9102 - val_loss: 0.3202 - val_acc: 0.8872\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.2462 - acc: 0.9118 - val_loss: 0.3059 - val_acc: 0.8916\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 8s 141us/sample - loss: 0.2420 - acc: 0.9126 - val_loss: 0.3044 - val_acc: 0.8950\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 8s 148us/sample - loss: 0.2386 - acc: 0.9141 - val_loss: 0.2996 - val_acc: 0.8942\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.2347 - acc: 0.9153 - val_loss: 0.3143 - val_acc: 0.8852\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.2298 - acc: 0.9175 - val_loss: 0.2947 - val_acc: 0.8950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=30, validation_data=(X_valid,y_valid), verbose=1, batch_size=32)\n",
    "# set class_weight if underrepresented classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(history.epoch,acc)\n",
    "plt.plot(history.epoch,val_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 64us/sample - loss: 2.3055 - acc: 0.8546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.305491944849483, 0.8546]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test[:3])\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\clmen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "WARNING:tensorflow:From C:\\Users\\clmen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 2.2589 - val_loss: 1.5993\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.8548 - val_loss: 0.7635\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.7383 - val_loss: 0.6978\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.6900 - val_loss: 0.6669\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.6513 - val_loss: 0.7204\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.6215 - val_loss: 0.5869\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5929 - val_loss: 0.5517\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5682 - val_loss: 0.5282\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5463 - val_loss: 0.5083\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5274 - val_loss: 0.4896\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5110 - val_loss: 0.4776\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4968 - val_loss: 0.4625\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4845 - val_loss: 0.4493\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4740 - val_loss: 0.4391\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4651 - val_loss: 0.4301\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4575 - val_loss: 0.4284\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4510 - val_loss: 0.4175\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - ETA: 0s - loss: 0.445 - 0s 37us/sample - loss: 0.4455 - val_loss: 0.4125\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4407 - val_loss: 0.4097\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4367 - val_loss: 0.4128\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionnal API\n",
    "\n",
    "build more complexe architecture with re-use of the inputs in the last layer to keep some simple relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 2.0912 - val_loss: 14.1523\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.7528 - val_loss: 1.8473\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6013 - val_loss: 0.7340\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5621 - val_loss: 0.5098\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5272 - val_loss: 0.4975\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5021 - val_loss: 0.4619\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.4812 - val_loss: 0.4407\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4646 - val_loss: 0.4527\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4509 - val_loss: 0.4199\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4404 - val_loss: 0.4140\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4319 - val_loss: 0.4334\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4248 - val_loss: 0.4339\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.4189 - val_loss: 0.4231\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4140 - val_loss: 0.4321\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4095 - val_loss: 0.4502\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4058 - val_loss: 0.4500\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4026 - val_loss: 0.4019\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3989 - val_loss: 0.4885\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3969 - val_loss: 0.3685\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3936 - val_loss: 0.4257\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAEvCAYAAACdahL0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5wcdZnv8c9T3T2XZGZyIwkzCRLkkkASkkBAUTckoAmIIuuqG0REBHOQVdE9sICeRd1z1PWwR3f3LMpBYfECSBZ0ZTWIKImIIkIwhECAhMglISQk5DKTZC7d/Zw/qmYyGWaSmemeqa7u7/v1qldV1/X3TM3M079f/arK3B0REREZXkHcBRAREalESsAiIiIxUAIWERGJgRKwiIhIDJSARUREYqAELCIiEoP0cB5s9OjRfswxxwznIWOzZ88eRo4cGXcxhlylxAmKtVxVSqyVEieUVqwrV67c5u7je1s2rAl44sSJPPbYY8N5yNisWLGC+fPnx12MIVcpcYJiLVeVEmulxAmlFauZvdjXMjVBi4iIxEAJWEREJAZKwCIiIjEY1mvAIiKSLB0dHWzcuJHW1ta4i9Jvo0aNYu3atcN6zJqaGiZPnkwmk+n3NkrAIiLSp40bN1JfX8+UKVMws7iL0y/Nzc3U19cP2/Hcne3bt7Nx40aOOuqofm+nJmgREelTa2sr48aNS0zyjYOZMW7cuAG3EigBi4jIQSn5HtpgfkZKwCIiUtLq6uriLsKQUAIWERGJwSETsJndYmZbzWxNL8uuNDM3s8P6c7B0du9gyigiIoK7c9VVVzFjxgxmzpzJnXfeCcDmzZuZN28es2fPZsaMGfz+978nl8vxsY99rGvdb37zmzGX/o360wv6VuDfgO93n2lmRwDvAl7q78EyHTsHUjYREZEuP/7xj1m1ahVPPPEE27Zt45RTTmHevHncfvvtLFq0iC984Qvkcjm2bNnCqlWr2LRpE2vWhHXHnTtLL/8cMgG7+4NmNqWXRd8E/g74aX8PFuSz/S6YiIiUli//11M8/cruou7zhKYGvvje6f1a96GHHuL8888nlUoxceJETj/9dB599FFOOeUUPv7xj9PR0cF5553H0UcfTW1tLRs2bODTn/4055xzDgsXLixquYthUNeAzexcYJO7PzGg7Tw3mMOJiIjg7r3OnzdvHg8++CCTJk3iwgsv5Pbbb2fMmDE88cQTzJ8/nxtuuIFLL710mEt7aNZXQAesFNaAf+buM8xsBLAcWOjuu8zsBWCuu2/rY9slwBKAkxuDk7/xg2XkU9VFKn7pamlpKduee91VSpygWMtVpcQ62DhHjRpF3K+RbWxsZPPmzdxzzz3ccsst3H333ezYsYPTTz+dBx54gLa2Npqamkin09xwww28+OKLXH311WQyGRoaGli9ejWf/OQn+d3vfjek5Vy/fj27du06YN6CBQtWuvvcXjdw90MOwBRgTTQ9E9gKvBANWcLrwIcfaj8nNwbu29Z7JVi+fHncRRgWlRKnu2ItV5US62DjfPrpp4tbkEEYOXKku7vn83m/8sorffr06T5jxgz/0Y9+5O7ut956q0+fPt1nz57t73jHO3z16tW+atUqnzNnjs+aNctnzZrly5YtG/Jy9vazAh7zPnLigB9F6e5PAhM6Px+qBvwGuzfBuKMHelgREalQLS0tQPiwi+uvv57rr7/+gOUXXXQRF110UdfnzkdRPv7448NazoHqz21IdwAPA1PNbKOZXVLQEXdvLmhzERGRctCfXtDnH2L5lAEdsfmVAa0uIiJSjob1SVhugWrAIiIiDHsCTofXgEVERCrcsCbgfJCGZtWARUREYqgBKwGLiIgMfwJu2QI5PZJSREQq2zA3QafAc7Bn63AeVkREKsTBnvb1wgsvMGPGjGEszcENfw0Y1AwtIiIVb3gTcBAlYN0LLCIi/XD11VfzrW99q+vzl770Jb785S9z5plnctJJJzFz5kx++tN+v5SvS2trKxdffDEzZ85kzpw5LF++HICnnnqKU089ldmzZ3PiiSeybt069uzZwznnnMOsWbOYMWNG13uICzXgR1EWIt9VA1YCFhFJnHuvgVefLO4+D58JZ/9jn4sXL17MZz/7WS6//HIAli5dyi9+8Qs+97nP0dDQwLZt23jrW9/Kueeei5n1+7A33HADAE8++STPPPMMCxcu5LnnnuPGG2/kiiuu4IILLqC9vZ1cLseyZctoamri5z//OcAbXrgwWMPcBJ2CIKMELCIi/TJnzhy2bt3KK6+8whNPPMGYMWNobGzk85//PCeeeCLvfOc72bRpE1u2bBnQfh966CEuvPBCAKZNm8aRRx7Jc889x2mnncZXv/pVvv71r/Piiy9SW1vLzJkz+dWvfsXVV1/Nb3/7W0aNGlWU2Ia1BgxAfaPuBRYRSaKD1FSH0gc+8AHuuusuXn31VRYvXsxtt93Ga6+9xsqVK8lkMkyZMoXW1tYB7dP7eBXvhz/8Yd7ylrfw85//nEWLFvHd736XM844g5UrV7Js2TKuvfZaFi5cyHXXXVdwXMOfgBsaVQMWEZF+W7x4MZ/4xCfYtm0bv/nNb1i6dCkTJkwgk8mwfPlyXnzxxQHvc968edx2222cccYZPPfcc7z00ktMnTqVDRs28OY3v5nPfOYzbNiwgdWrVzNt2jTGjh3LRz7yEerq6rj11luLElcMCbgJNq8e9sOKiEgyTZ8+nebmZiZNmkRjYyMXXHAB733ve5k7dy6zZ89m2rRpA97n5ZdfzmWXXcbMmTNJp9PceuutVFdXc+edd/LDH/6QTCbD4YcfznXXXcejjz7KVVddRRAEZDIZvv3tbxclrhiaoJvgufvAHQZwwVxERCrXk0/u7/x12GGH8fDDD/e6XktLC83Nzb0umzJlCmvWrAGgpqam15rstddey7XXXnvAvEWLFrFo0aJBlrxvw9oJCwiboDv2QmtxepGJiIgkUTydsCDsiFU7etgPLyIi5e2pp57isssuO2BedXU1jzzySEwl6l0M14AnhePdm2DC8cN+eBERKW/Tp09n1apVcRfjkOJpggY9jlJEJCH6umVH9hvMz2j4E3D3JmgRESlpNTU1bN++XUn4INyd7du3U1NTM6Dthr8JOl0NI8aFTdAiIlLSJk+ezMaNG3nttdfiLkq/tba2DjgZFqqmpobJkycPaJvhT8AQ3gusJmgRkZKXyWQ46qij4i7GgKxYsYI5c+bEXYxDGv4maAjvBdYbkUREpILFk4AbGlUDFhGRihZfDXjvNsi2xXJ4ERGRuMVUA24Kx+oJLSIiFSq+JmhQM7SIiFSs+JqgQR2xRESkYh0yAZvZLWa21czWdJt3vZk9Y2arzewnZjawhzp3NkHrvcAiIlKh+lMDvhU4q8e8+4EZ7n4i8Bxwbc+NDqpmFGRGqAlaREQq1iETsLs/CLzeY94v3T0bffwDMLDHf5iFj6RUE7SIiFSoYlwD/jhw74C30tOwRESkgll/HrBtZlOAn7n7jB7zvwDMBd7vfezIzJYASwDGjx9/8tKlSwGYtvabjN75NH847TuFlL9ktbS0UFdXF3cxhlylxAmKtVxVSqyVEieUVqwLFixY6e5ze1s26GdBm9lFwHuAM/tKvgDufhNwE8DUqVN9/vz54YKO5fDw75g/bx4E8XTGHkorVqygK9YyVilxgmItV5USa6XECcmJdVCZz8zOAq4GznX3vYM6ckMT5Dtg7/ZBbS4iIpJk/bkN6Q7gYWCqmW00s0uAfwPqgfvNbJWZ3TjgI3e+F1ivJRQRkQp0yCZodz+/l9k3F3zkhknhuHkzMLvg3YmIiCRJfBdfux5HqVuRRESk8sSXgEdOAAv0QgYREalI8SXgVBrqJqoGLCIiFSne+38ampSARUSkIsWbgOsb1QQtIiIVqQRqwErAIiJSeeJPwG27oK0l1mKIiIgMt5iboKP3AqsZWkREKkzMNWDdCywiIpVJNWAREZEYlEgNWM+DFhGRyhJvAq4aCTWj1BNaREQqTvwv4q1vUhO0iIhUnPgTcEOjmqBFRKTilEAC1sM4RESk8sSfgOubYM9WyGXjLomIiMiwiT8BNzSC56FlS9wlERERGTYlkIAnhWM9jENERCpI/Am4ProXuFkJWEREKkf8CbghehqWOmKJiEgFiT8BjxgHqSrVgEVEpKLEn4DNwmZoXQMWEZEKEn8CBt0LLCIiFac0EnB9o5qgRUSkopRGAm5oCpug3eMuiYiIyLAonQScbYV9O+IuiYiIyLAojQTcdS+wrgOLiEhlOGQCNrNbzGyrma3pNm+smd1vZuui8ZiCSqF7gUVEpML0pwZ8K3BWj3nXAL9292OBX0efB6+zBqzXEoqISIU4ZAJ29weB13vMfh/wvWj6e8B5BZVCTdAiIlJhBnsNeKK7bwaIxhMKKkW6CkaO18M4RESkYpj349YfM5sC/MzdZ0Sfd7r76G7Ld7h7r9eBzWwJsARg/PjxJy9durTXY5z82OdorxrDkydeN9AYSlJLSwt1dXVxF2PIVUqcoFjLVaXEWilxQmnFumDBgpXuPre3ZelB7nOLmTW6+2YzawS29rWiu98E3AQwdepUnz9/fu8rvjIVdr1Mn8sTZsWKFWUTy8FUSpygWMtVpcRaKXFCcmIdbBP0PcBF0fRFwE8LLkmDngctIiKVoz+3Id0BPAxMNbONZnYJ8I/Au8xsHfCu6HNh6ptg3+vQ0VrwrkRERErdIZug3f38PhadWdSSNHTrCT32qKLuWkREpNSUxpOwoNvDONQMLSIi5a90EnB9lIB1L7CIiFSA0knAnU3QqgGLiEgFKJ0EXN0AmZFKwCIiUhFKJwGbhdeBm5WARUSk/JVOAoboXmBdAxYRkfJXWgm4vkmdsEREpCKUVgJuaAwTcD4fd0lERESGVIkl4EmQz8Ke1+IuiYiIyJAqrQTc9V5gdcQSEZHyVloJuOteYF0HFhGR8lZiCXhSON69Kd5yiIiIDLHSSsAjx4Ol1BNaRETKXmkl4CAF9YerCVpERMpeaSVgCDtiqROWiIiUudJLwA1Neh60iIiUvRJNwGqCFhGR8lZ6Cbi+EdqboXV33CUREREZMqWXgBuawrF6QouISBkr3QSs68AiIlLGSi8Bdz2OUjVgEREpX6WXgFUDFhGRClB6CThTCzWjlYBFRKSslV4ChvCZ0GqCFhGRMlaiCbhRNWARESlrpZmA6xtVAxYRkbJWmgm4YRK0bIVcR9wlERERGRIFJWAz+5yZPWVma8zsDjOrKUqpGhoBh+ZXi7I7ERGRUjPoBGxmk4DPAHPdfQaQAhYXpVT1ehqWiIiUt0KboNNArZmlgRFAcXpONUQP49i9qSi7ExERKTWDTsDuvgn4J+AlYDOwy91/WZRSNUwKx3orkoiIlClz98FtaDYGuBv4a2An8B/AXe7+wx7rLQGWAIwfP/7kpUuXHnrn7sx78INsnHwOG46+eFDli1tLSwt1dXVxF2PIVUqcoFjLVaXEWilxQmnFumDBgpXuPre3ZekC9vtO4M/u/hqAmf0YeBtwQAJ295uAmwCmTp3q8+fP79/eV0/iTaPSvKm/65eYFStW0O9YE6xS4gTFWq4qJdZKiROSE2sh14BfAt5qZiPMzIAzgbXFKRZhRyw9jENERMpUIdeAHwHuAh4Hnoz2dVORyhW+lKFZCVhERMpTIU3QuPsXgS8WqSwHamiEtZvBHcyG5BAiIiJxKc0nYUHYBJ1rg3074i6JiIhI0ZVuAu56L7DuBRYRkfKTgASse4FFRKT8lG4Cro+ehqWOWCIiUoZKOAEfDphqwCIiUpZKNwGnMlA3QdeARUSkLJVuAoawGVpvRBIRkTJU2gm4oUlN0CIiUpZKOwHXN6oJWkREylJpJ+CGJmjdCR374i6JiIhIUZV+Aga9lEFERMpOaSfgrnuBdR1YRETKS2knYNWARUSkTCkBi4iIxKC0E3B1PVTVqwlaRETKTmknYAjfC6wasIiIlJkEJOAmJWARESk7pZ+A65vUBC0iImWn9BNwQyM0vwr5XNwlERERKZrST8D1jeA52PNa3CUREREpmtJPwA2TwrGeCS0iImUkAQk4ehqW3ookIiJlpPQTcH30MA51xBIRkTJS+gl45HgI0mqCFhGRslL6CTgIovcCqwYsIiLlo/QTMIQJuFkP4xARkfKRjATcoBqwiIiUl4ISsJmNNrO7zOwZM1trZqcVq2AHqI8eR+k+JLsXEREZbukCt/8X4Bfu/gEzqwJGFKFMb9TQBB17oG031IwakkOIiIgMp0HXgM2sAZgH3Azg7u3uvrNYBTtA13uB1QwtIiLlwXyQzbpmNhu4CXgamAWsBK5w9z091lsCLAEYP378yUuXLh3wsUbtfIo5qz7PEyd+mR1jZw+qvMOtpaWFurq6uIsx5ColTlCs5apSYq2UOKG0Yl2wYMFKd5/b60J3H9QAzAWywFuiz/8C/M+DbXPcccf5oGzf4P7FBvfHfzC47WOwfPnyuIswLColTnfFWq4qJdZKidO9tGIFHvM+cmIhnbA2Ahvd/ZHo813ASQXsr2/1ehyliIiUl0EnYHd/FXjZzKZGs84kbI4uvkwN1I7VvcAiIlI2Cu0F/WngtqgH9Abg4sKL1IeGJtWARUSkbBSUgN19FeG14KHX0KTnQYuISNlIxpOwIHocpWrAIiJSHpKTgBuaYM9rkG2PuyQiIiIFS04C7uwJrVqwiIiUgeQk4IZJ4VgJWEREykCCEnDnvcC6FUlERJIvOQlYTdAiIlJGkpOAa8dAukY1YBERKQvJScBm0b3ASsAiIpJ8yUnAAPVNaoIWEZGykKwE3NCoGrCIiJSFhCXgqAY8yHcYi4iIlIpkJeD6Jsi1w97tcZdERESkIMlKwLoXWEREykSyEnB9UzhWAhYRkYRLVgJuiBJwsxKwiIgkW7IScN1EsAB261YkERFJtmQl4FQaRk5QDVhERBIvWQkYdC+wiIiUhQQm4ElqghYRkcRLXgKub1QTtIiIJF7yEnBDI7TugvY9cZdERERk0JKXgLvuBVYztIiIJFfyErDuBRYRkTKQ3ASsGrCIiCRY8hJwffQ8aNWARUQkwZKXgKvroHqU7gUWEZFES14CBj2MQ0REEq/gBGxmKTP7k5n9rBgF6pf6RmjWNWAREUmuYtSArwDWFmE//dfQpBqwiIgkWkEJ2MwmA+cA3y1OcfqpoQlatkAuO6yHFRERKRZz98FvbHYX8DWgHrjS3d/TyzpLgCUA48ePP3np0qWDPl6npk33cty6G/n9abfQXj2u4P0NhZaWFurq6uIuxpCrlDhBsZarSom1UuKE0op1wYIFK919bm/L0oPdqZm9B9jq7ivNbH5f67n7TcBNAFOnTvX58/tctf+e3QfrbuRt06fA5JML398QWLFiBUWJtcRVSpygWMtVpcRaKXFCcmItpAn67cC5ZvYC8CPgDDP7YVFKdSid9wLv3jQshxMRESm2QSdgd7/W3Se7+xRgMfCAu3+kaCU7mIZJ4Vg9oUVEJKGSeR/wiHEQZNQTWkREEmvQ14C7c/cVwIpi7KtfgkD3AouISKIlswYMuhdYREQSLcEJWI+jFBGR5EpuAq5vCpugC7iPWUREJC7JTcANjdCxF1p3xV0SERGRAUtwAm4Kx2qGFhGRBEpuAq6PEnCzErCIiCRPchNwQ+fTsHQrkoiIJE9yE3DX4yhVAxYRkeRJbgJOV8OIw9QELSIiiZTcBAzRvcBqghYRkeRJdgKub1INWEREEinZCVhPwxIRkYRKeAKeBHu3Q7Yt7pKIiIgMSLITcGdPaL0VSUREEibZCVj3AouISEIlPAFPCse7N8VbDhERkQFKdgJWE7SIiCRUshNwzSjIjFATtIiIJE6yE7BZWAtWE7SIiCRMshMwhK8lVBO0iIgkTHkkYDVBi4hIwiQ/Adc3hjXgfD7ukoiIiPRb8hNwQxPkO2DvtrhLIiIi0m/lkYBBz4QWEZFESX4Cro8SsDpiiYhIgiQ/AXc9jlI1YBERSY5BJ2AzO8LMlpvZWjN7ysyuKGbB+m3kBLBACVhERBIlXcC2WeC/u/vjZlYPrDSz+9396b42yHkBR+tLKg11h6sJWkREEmXQNWB33+zuj0fTzcBaYNLBtnl1T56tza2DPWTfGhpVAxYRkUQpyjVgM5sCzAEeOdh62Txc8J1H2NbSVozD7td5L7CIiEhCmHth7cJmVgf8BviKu/+4l+VLgCUAYyY0nnzYJd9hwgjj6lNrqa+ygo7d6Zh1N3H4q8t56C/uKMr+iqGlpYW6urq4izHkKiVOUKzlqlJirZQ4obRiXbBgwUp3n9vrQncf9ABkgPuAv+3P+scdd5w/tO41P+4Ly/zsf37Qd+xp86L47Tfcv9jg3tpcnP0VwfLly+MuwrColDjdFWu5qpRYKyVO99KKFXjM+8iJhfSCNuBmYK27f6O/2739mMO46aNzWb+1hQtv/iO79nUMtgj7dd4LvGll4fsSEREZBoVcA347cCFwhpmtioZ392fD048bz40XnsQzr+7molv+SHNrgUn46AUw6gi4YzGs/Vlh+xIRERkGhfSCfsjdzd1PdPfZ0bCsv9ufMW0iN3z4JNZs2sXF//4oe9qygy0K1E2AS38NE46HOz8Cv/tXKPDatoiIyFCK9UlYC6cfzr+eP4c/vbyTi299lL3tBSTh+onwsZ/D9PPg/r+H//oM5IrQvC0iIjIEYn8U5btnNvLNv57NYy+8zqXfe4zWjtzgd5aphb+6BeZdBY9/H374fti3o3iFFRERKZLYEzDAubOa+KcPzuLhDdv5xPcLTMJBAGf8DzjvRnjxYfjuu+D1DcUrrIiISBGURAIGeP9Jk/n6+0/kt+u28ckfrqQtW0ASBph9Pnz0p+F7gr9zJrz4++IUVEREpAhKJgEDfOiUI/jqX85k+bOv8anb/0RHLl/YDqe8PeycNWIsfP998MSdxSmoiIhIgUoqAQN8+C1v4h/eN537n97CZ+4oQhIedzRccj8c8Rb4yRJ44H9BvsB9ioiIFKjkEjDAR0+bwt+/5wTuXfMqf7v0CbKFJuERY+EjP4Y5H4EHr4e7L4GOfcUprIiIyCAU8jrCIXXJO44im8vztXufIR0Y//TBWaSCAp4dna6Cc/8Nxh0Lv/oi7HoZFt8e3kMsIiIyzEqyBtzpv51+NFctmspP/rSJa+5eTT5f4MM1zOAdn4UP/QBeXRN2ztrS5+uLRUREhkxJJ2CAv1lwDJ9957H8x8qNfOE/1xSehAFOOBcuXga5Nrh5Iaz/VeH7FBERGYCST8AAV5x5LH+z4Gju+ONLfPGepzrfxFSYSSfBJx6AMVPgtg/BH79T+D5FRET6qWSvAXdnZly5cCrZnPP/HtxAOmVc954TCF/IVIBRk+Hj98Jdl8CyK2H787DoKxCkilNwERGRPiQiAUOYhK85exodOeeW3/2ZqlTANWdPKzwJV9fD+XfAL/8H/OFb4VOzPnBzOF9ERGSIJCYBQ5iE//49x5PN57tqwlcunFp4Eg5ScNbXwnuGl/0d3HIWfPjOsIYsIiIyBBJxDbg7M+NL753O+ae+iRuWP8+//Hpd8XZ+yqVwwVLY+RJ85wzYtLJ4+xYREekmcQkYIAiMr5w3gw/Nncw//2odNyxfX7ydH/NOuOSXkK6Gfz8Hnv5p8fYtIiISSWQChjAJf+39J/L+OZO4/r5nuWH5el7f016cHtITjodLH4DDZ8DSj8JvvwHF2K+IiEgkUdeAe0oFxvUfnEVH3rn+vme5/r5nqckENI2qpWl0LU2ja2gcVcuk0bU0jq4J542qpbaqH72c68bDRf8F/3k5/PrLYU248USYcEKYoCecACPHhw/3EBERGaBEJ2AIk/A3PzSLv5zTxIvb9/LKzn28srOVV3bt4zfPvcbW5rY3VF7HjMjQNLo2Ss41NI6OEvaoMElPqK8mnQogUwt/dTNMOhmevRfW/gwe//7+HY0YB+OPjxJylJQnTIPaMcP7QxARkcRJfAIGSKcCzpg2sddl7dk8W3a38srOfWze1cqmnfvYvCtM0ht37OWPf97O7tbsAdukAmNifXWYpEfX0jT6TEYfdTbVxxijfCeH7X2esXueZ0zLeup3r2PkK3eQ7mjp2j47spHj0xNpbTkNm3g8qcOnk554PFSNHNKfg4iIJEdZJOCDqUoHHDF2BEeMHdHnOi1tWTbv3Bcl5zBZb9q5j807W1m9cSf3rWml/YA3Mo0AZkYDgNPEdo4LXmaqbeS43S9znG1k1KPfpdo6urZ6ySeywSbzQnAkL6WP5OXMFLZWvYkgU01VKqAqHVCdDseZVNA1r3OoTkXzu83rWid14LxMNK6O9pVOGZlUQCowMkH4OZ0Kp4NCXnIhIiKDUvYJuD/qqtMcO7GeYyf2/vANd6ctm6etI09bNhdOZ/dPt3d+7sjRngvXu/vptRx11FFUNb9M/e51jG5Zz5g9z3P83uf5i9ZVpNpz0A65PQHbUofTZhnybuQwch5E4/1DloBcPlyeJ8AxcgTko895Atow9nXNC5c7AR2eop007WTCsWe6ptvIkCVNNqgiZxlyQRX5oIpcEE57UEU+VU0+yECqGk9X4UE1pDN4UMWuXa3c/tJjpFNGKghIB0YqsB7jgEzqwM/pVO/rpQPrtiwgFUBg4eeuwYwg2iaIPndf3rW+GalU5/qQsnCfQcAb1jOj8PvJRWTw8jlo3QX7doTj1p2wb2c47mgNL/nVTYiGiVA7FoLE9iMGlID7xcyoyaSoyaSATL+2Gde8nvnvOAY4Blhw4MJsO2xfD6+tJbV1LRO3Pw/5LHh+/5DPRdOdY8fzWdzzeD6P53PRuCMcR9scMI6mLZ8lyLcT5NtJ5TsIPNtbkffLR0M/ZEmRbU6Ro/sQhPNJkSUg69GYFFnvtswDctF05zad43ZPsZews1yAk7J811ePVNdXkDwpPPrKsX9+0PWVxAnM9093m58ijwHtpGgnQ4en6bA0HWToIE2WDFlLk43mZS1DW9549rd3kCNNR1BFjjS5IFyWswx5y5ANoukggwcpjCDsp2cBZhYmeQvADLMgSvxB1/zu6wTRtFkAgRFYEO9oWy0AAAs1SURBVK4bABgp8qTJE5AjTT766edJeZaUefjT9Bzp6KtaqnPsuQOmA3Jd4855rdu38ejLvwrLF/0NdH49Cb+nWDQfDI/mR+tE29DLduG0Rf84DSwFQefPJAg/m2Gd80ntXzfoXB5gQdBtm/2DBSkMD8vk4di88yupY+7RdB5zB5yqF55ny2/WR+vnu22fj7b1aN1wG/Pwb9XyWcxzXQP5znHn/HzX9IHL8l1/75bPguewfC78W+/8WR7kb856rmEHX7/T7N3N8NLEsG9LphbStZCp6TbdOb8GMiOiZSMO/NxzWarqwI6ouY4oie48MIF2n37DOEq2bbv7EUX3H0Qq7AhbNz5MyCMndCXoCVu2wQbrlqzHDF2HWXfItkL7XmhvgY694XTHnnB8EErAcUhXwcQTwmEAjP79oR1SPh++CSrbBrn2HuO28AvCAeO+19v05/UcObkp/MKQz0ZDR4/P2QM+e64Dz2Xxrs9ZyLd3fSYXji2fDf8dWZg+3aIBwy2Fm+2fT4Db/pTsloqmjbxF464UHnT9mx2Z7yDId2DeQSrXTuB7SeXbSXmWIN9B2tsJPEs6307KOghyUY++XDFORInbGXcBhkcjwAuD377zi2T45TH8itf5ZTJHQM67TdP7unkCch5EXwsL01ueMcJ7Tmt2bKTG2qmmnVraqKGDGtqotfZBHSuP0UYVrVRRRQcjaT3o+q1U0cxImq2u2/jNNNtIWtJ1NFs4r4U6WoI6WqyOZuroCKoY47uiYQdjfSdjfCdj23YwZt8uxmx9gbG+ijG+kwxZTgBY+42u42ZJscNGs9NGsyMYw45gNDssHO+00bgF1HgrNd5KLfvH1d4WTnsrNdH8znk10bwqbyPV3xpLD0rAlSgIIIi+7Rboz7aCI+fPH9A2RfsiMcxWrFjB/Hl/sf+LSK4j/CKSa4++rHSbl22LWi+AqDbWNfb8G+f1uoyDLwvS4WNUg1Q0nY5qlN0+97JO+OUlRT4aPEjhFtal3VLkLOB3v3+Et532Nhwn7+FlmLyD4+B0TXcucywsYo/1wfHu6+cB8ng+jKuzJQcPW3XwfFfrzf75+1tznDyWz5PvauHJ44Rjopqmd9Vhwy9n+aiO3vklzb3zy1q43nPrnufo444j7wbdl5vhbl1f2Lrqxp0/u672lPC32aNYPTpvHp0+j6Y7T2c437t97rZdt3ldp/8N63ebH20b/ZZ1HbfnvgFefPEl3nTkmw7YP932H+TbyORbSefaSOejIddKxttI5Vu7lmXybWQ8WpZvJe3tpHOt5IIM+1L17A3q2Zeu3z+dqmNvUE9rqo4Oq+473m5FcndSwCigoWvRZLLuvAa8tr/oPeLIU5tvoWPr80xpgIbcDhpyr1OfDccNuR1MzO3g2OwLNOR2kOrjm3Qeo91qaLMa2oJobDW0pkawx8Z2fW6zatqCGlqtNlzeOS+abqUGuLjXY4ASsMjABCmoGkHYES+ZOr8AHezqWW11FaMa6oapRPEK2luZf9opcRdjyK1Y8Srz50+LuxjDYsUKmH+oikE+HzZ9t2wFPGxSrxoJmREEmVpqzKgpQlm+8mklYBERkf2CAEaMDYe4ilDIxmZ2lpk9a2brzeyaYhVKRESk3A06AZtZCrgBOBs4ATjfzAbWq0hERKRCFVIDPhVY7+4b3L0d+BHwvuIUS0REpLwVkoAnAS93+7wxmiciIiKHYIN9fZ+ZfRBY5O6XRp8vBE5190/3WG8JsARg/PjxJy9durSwEidES0sLdXXl34u0UuIExVquKiXWSokTSivWBQsWrHT3ub0tK6QX9EbgiG6fJwOv9FzJ3W8CbgKYOnWqH7JreJlYsWLFobvBl4FKiRMUa7mqlFgrJU5ITqyFNEE/ChxrZkeZWRWwGLinOMUSEREpb4OuAbt71sw+BdwHpIBb3P2popVMRESkjBX0IA53XwYsK1JZREREKkay3+UkIiKSUIPuBT2og5k1A88O2wHjdRiwLe5CDINKiRMUa7mqlFgrJU4orViPdPfxvS0Y7mdBP9tXd+xyY2aPVUKslRInKNZyVSmxVkqckJxY1QQtIiISAyVgERGRGAx3Ar5pmI8Xp0qJtVLiBMVariol1kqJExIS67B2whIREZGQmqBFRERiMCQJ2MzOMrNnzWy9mV3Ty/JqM7szWv6ImU0ZinIMJTM7wsyWm9laM3vKzK7oZZ35ZrbLzFZFw3VxlLUYzOwFM3syiuOxXpabmf1rdE5Xm9lJcZSzUGY2tdv5WmVmu83ssz3WSex5NbNbzGyrma3pNm+smd1vZuui8Zg+tr0oWmedmV00fKUenD5ivd7Mnol+R39iZqP72Pagv++lpI84v2Rmm7r9jr67j20P+r+61PQR653d4nzBzFb1sW3pnVN3L+pA+FjK54E3A1XAE8AJPda5HLgxml4M3Fnscgz1ADQCJ0XT9cBzvcQ5H/hZ3GUtUrwvAIcdZPm7gXsBA94KPBJ3mYsQcwp4lfA+vrI4r8A84CRgTbd5/xu4Jpq+Bvh6L9uNBTZE4zHR9Ji44xlErAuBdDT99d5ijZYd9Pe9lIY+4vwScOUhtjvk/+pSG3qLtcfy/wNcl5RzOhQ14FOB9e6+wd3bgR8B7+uxzvuA70XTdwFnmpkNQVmGjLtvdvfHo+lmYC2V/T7k9wHf99AfgNFm1hh3oQp0JvC8u78Yd0GKxd0fBF7vMbv73+P3gPN62XQRcL+7v+7uO4D7gbOGrKBF0Fus7v5Ld89GH/9A+Ba3ROvjnPZHf/5Xl5SDxRrlkA8BdwxroQowFAl4EvByt88beWNi6lon+mPYBYwbgrIMi6gJfQ7wSC+LTzOzJ8zsXjObPqwFKy4HfmlmK6N3PPfUn/OeNIvp+4+5XM4rwER33wzhF0tgQi/rlOP5/Thhq01vDvX7ngSfiprab+njskK5ndO/ALa4+7o+lpfcOR2KBNxbTbZnV+v+rJMIZlYH3A181t1391j8OGHz5Szg/wL/OdzlK6K3u/tJwNnA35jZvB7Ly+acAkSv2DwX+I9eFpfTee2vcju/XwCywG19rHKo3/dS923gaGA2sJmwabansjqnwPkcvPZbcud0KBLwRuCIbp8nA6/0tY6ZpYFRDK4JJVZmliFMvre5+497Lnf33e7eEk0vAzJmdtgwF7Mo3P2VaLwV+Alh81V3/TnvSXI28Li7b+m5oJzOa2RL5+WCaLy1l3XK5vxGHcjeA1zg0cXBnvrx+17S3H2Lu+fcPQ98h97LX07nNA28H7izr3VK8ZwORQJ+FDjWzI6KahGLgXt6rHMP0NmL8gPAA339IZSq6HrDzcBad/9GH+sc3nlt28xOJfx5bx++UhaHmY00s/rOacKOLGt6rHYP8NGoN/RbgV2dzZoJ1ee36XI5r910/3u8CPhpL+vcByw0szFRc+bCaF6imNlZwNXAue6+t491+vP7XtJ69L/4S3ovf3/+VyfFO4Fn3H1jbwtL9pwOUU+1dxP2Cn4e+EI07x8If+kBagib9tYDfwTeHHdvtEHE+A7C5prVwKpoeDdwGXBZtM6ngKcIexf+AXhb3OUeZKxvjmJ4Ioqn85x2j9WAG6Jz/iQwN+5yFxDvCMKEOqrbvLI4r4RfKjYDHYQ1oEsI+1/8GlgXjcdG684Fvttt249Hf7PrgYvjjmWQsa4nvO7Z+TfbeTdGE7Asmu71971Uhz7i/EH0d7iaMKk29owz+vyG/9WlPPQWazT/1s6/z27rlvw51ZOwREREYqAnYYmIiMRACVhERCQGSsAiIiIxUAIWERGJgRKwiIhIDJSARUREYqAELCIiEgMlYBERkRj8f//r2OCHSlR7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build more complexe architecture spliting the features. Some are use during the whole process and other are use only in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 78us/sample - loss: 2.3538 - val_loss: 1.0793\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.8870 - val_loss: 0.7795\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.7280 - val_loss: 0.6834\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.6684 - val_loss: 0.6324\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.6301 - val_loss: 0.5958\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.6001 - val_loss: 0.5714\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5747 - val_loss: 0.5401\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5528 - val_loss: 0.5180\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.5329 - val_loss: 0.4993\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.5156 - val_loss: 0.4811\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.5002 - val_loss: 0.4691\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4867 - val_loss: 0.4562\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4752 - val_loss: 0.4451\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4651 - val_loss: 0.4337\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4567 - val_loss: 0.4279\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4494 - val_loss: 0.4241\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4429 - val_loss: 0.4166\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4376 - val_loss: 0.4113\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4328 - val_loss: 0.4106\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4288 - val_loss: 0.4053\n",
      "5160/5160 [==============================] - 0s 20us/sample - loss: 0.4199\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs auxilaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "aux_output = keras.layers.Dense(1)(hidden2)\n",
    "\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 1.0195 - output_loss: 0.9159 - dense_12_loss: 1.9496 - val_loss: 17.0193 - val_output_loss: 18.7107 - val_dense_12_loss: 1.7114\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.6544 - output_loss: 0.6080 - dense_12_loss: 1.0693 - val_loss: 2.2929 - val_output_loss: 2.4438 - val_dense_12_loss: 0.9244\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4910 - output_loss: 0.4503 - dense_12_loss: 0.8578 - val_loss: 1.7504 - val_output_loss: 1.8202 - val_dense_12_loss: 1.1156\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4560 - output_loss: 0.4235 - dense_12_loss: 0.7486 - val_loss: 0.7665 - val_output_loss: 0.7711 - val_dense_12_loss: 0.7224\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4397 - output_loss: 0.4136 - dense_12_loss: 0.6732 - val_loss: 0.5359 - val_output_loss: 0.5177 - val_dense_12_loss: 0.6988\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4264 - output_loss: 0.4037 - dense_12_loss: 0.6291 - val_loss: 0.4568 - val_output_loss: 0.4420 - val_dense_12_loss: 0.5893\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4191 - output_loss: 0.3993 - dense_12_loss: 0.5981 - val_loss: 0.3916 - val_output_loss: 0.3716 - val_dense_12_loss: 0.5711\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4081 - output_loss: 0.3888 - dense_12_loss: 0.5821 - val_loss: 0.4086 - val_output_loss: 0.3932 - val_dense_12_loss: 0.5473\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4073 - output_loss: 0.3892 - dense_12_loss: 0.5692 - val_loss: 0.4162 - val_output_loss: 0.3982 - val_dense_12_loss: 0.5782\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4020 - output_loss: 0.3842 - dense_12_loss: 0.5606 - val_loss: 0.3856 - val_output_loss: 0.3680 - val_dense_12_loss: 0.5440\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3972 - output_loss: 0.3797 - dense_12_loss: 0.5544 - val_loss: 0.4473 - val_output_loss: 0.4299 - val_dense_12_loss: 0.6018\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3942 - output_loss: 0.3768 - dense_12_loss: 0.5511 - val_loss: 0.3893 - val_output_loss: 0.3689 - val_dense_12_loss: 0.5727\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3881 - output_loss: 0.3711 - dense_12_loss: 0.5398 - val_loss: 0.3784 - val_output_loss: 0.3605 - val_dense_12_loss: 0.5414\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3843 - output_loss: 0.3679 - dense_12_loss: 0.5318 - val_loss: 0.3839 - val_output_loss: 0.3688 - val_dense_12_loss: 0.5207\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3898 - output_loss: 0.3746 - dense_12_loss: 0.5263 - val_loss: 0.3621 - val_output_loss: 0.3407 - val_dense_12_loss: 0.5538\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3771 - output_loss: 0.3610 - dense_12_loss: 0.5227 - val_loss: 0.3673 - val_output_loss: 0.3520 - val_dense_12_loss: 0.5041\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3764 - output_loss: 0.3612 - dense_12_loss: 0.5148 - val_loss: 0.3999 - val_output_loss: 0.3756 - val_dense_12_loss: 0.6172\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3732 - output_loss: 0.3581 - dense_12_loss: 0.5100 - val_loss: 0.6302 - val_output_loss: 0.6403 - val_dense_12_loss: 0.5380\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3708 - output_loss: 0.3564 - dense_12_loss: 0.5047 - val_loss: 0.4488 - val_output_loss: 0.4427 - val_dense_12_loss: 0.5039\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3695 - output_loss: 0.3549 - dense_12_loss: 0.5001 - val_loss: 0.5798 - val_output_loss: 0.5908 - val_dense_12_loss: 0.4783\n"
     ]
    }
   ],
   "source": [
    "# preciser loss pour chaque output, donner un poids\n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "\n",
    "# donner y_train et y_val plusieurs fois\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 39us/sample - loss: 0.3640 - output_loss: 0.3515 - dense_12_loss: 0.4769\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    \"\"\"\n",
    "        - Split the creation of the model from their usage (with a specific input) \n",
    "    \"\"\"\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs) # handle standard args\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A,hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        \n",
    "        return main_output, aux_output\n",
    "\n",
    "#model = WideAndDeepModel(units=30, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Savings and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], \n",
    "                    epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), \n",
    "                    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model only\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], \n",
    "                    epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), \n",
    "                    callbacks=[checkpoint_cb])\n",
    "\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], \n",
    "                    epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), \n",
    "                    callbacks=[checkpoint_cb,early_stopping_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "    print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définir le root log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2019_09_07-14_59_01'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_dir(root_logdir):\n",
    "    import time\n",
    "    \n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir,run_id)\n",
    "\n",
    "run_logdir = get_run_dir(root_logdir)\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3718 - output_loss: 0.3574 - dense_18_loss: 0.5019 - val_loss: 0.3842 - val_output_loss: 0.3667 - val_dense_18_loss: 0.5410\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3810 - output_loss: 0.3681 - dense_18_loss: 0.4973 - val_loss: 0.3754 - val_output_loss: 0.3567 - val_dense_18_loss: 0.5440\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3683 - output_loss: 0.3546 - dense_18_loss: 0.4908 - val_loss: 0.4021 - val_output_loss: 0.3848 - val_dense_18_loss: 0.5565\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3673 - output_loss: 0.3542 - dense_18_loss: 0.4857 - val_loss: 0.3559 - val_output_loss: 0.3379 - val_dense_18_loss: 0.5172\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 85us/sample - loss: 0.3630 - output_loss: 0.3501 - dense_18_loss: 0.4806 - val_loss: 0.4810 - val_output_loss: 0.4734 - val_dense_18_loss: 0.5482\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3636 - output_loss: 0.3511 - dense_18_loss: 0.4750 - val_loss: 0.3430 - val_output_loss: 0.3276 - val_dense_18_loss: 0.4813\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3573 - output_loss: 0.3449 - dense_18_loss: 0.4695 - val_loss: 0.3783 - val_output_loss: 0.3643 - val_dense_18_loss: 0.5036\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3633 - output_loss: 0.3518 - dense_18_loss: 0.4675 - val_loss: 0.3487 - val_output_loss: 0.3369 - val_dense_18_loss: 0.4537\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3552 - output_loss: 0.3434 - dense_18_loss: 0.4626 - val_loss: 0.3849 - val_output_loss: 0.3739 - val_dense_18_loss: 0.4839\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3522 - output_loss: 0.3403 - dense_18_loss: 0.4578 - val_loss: 0.3417 - val_output_loss: 0.3283 - val_dense_18_loss: 0.4623\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3509 - output_loss: 0.3395 - dense_18_loss: 0.4531 - val_loss: 0.3653 - val_output_loss: 0.3525 - val_dense_18_loss: 0.4812\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3483 - output_loss: 0.3372 - dense_18_loss: 0.4472 - val_loss: 0.3508 - val_output_loss: 0.3385 - val_dense_18_loss: 0.4610\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3484 - output_loss: 0.3378 - dense_18_loss: 0.4455 - val_loss: 0.3334 - val_output_loss: 0.3216 - val_dense_18_loss: 0.4385\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3457 - output_loss: 0.3348 - dense_18_loss: 0.4422 - val_loss: 0.3473 - val_output_loss: 0.3361 - val_dense_18_loss: 0.4500\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3460 - output_loss: 0.3359 - dense_18_loss: 0.4381 - val_loss: 0.3341 - val_output_loss: 0.3235 - val_dense_18_loss: 0.4285\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3422 - output_loss: 0.3320 - dense_18_loss: 0.4352 - val_loss: 0.3727 - val_output_loss: 0.3634 - val_dense_18_loss: 0.4557\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3399 - output_loss: 0.3297 - dense_18_loss: 0.4324 - val_loss: 0.3613 - val_output_loss: 0.3520 - val_dense_18_loss: 0.4438\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3388 - output_loss: 0.3288 - dense_18_loss: 0.4283 - val_loss: 0.4136 - val_output_loss: 0.4025 - val_dense_18_loss: 0.5136\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3387 - output_loss: 0.3290 - dense_18_loss: 0.4257 - val_loss: 0.3384 - val_output_loss: 0.3295 - val_dense_18_loss: 0.4175\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3355 - output_loss: 0.3257 - dense_18_loss: 0.4235 - val_loss: 0.3621 - val_output_loss: 0.3541 - val_dense_18_loss: 0.4386\n"
     ]
    }
   ],
   "source": [
    "# tensorflow callback for tensorboard : \n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], \n",
    "                    epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), \n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1,n_neurons=30, learning_rate=3e-3,input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\":input_shape}\n",
    "    \n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu',**options))\n",
    "        options={} # options uniquement pour le premiers layer.\n",
    "    model.add(keras.layers.Dense(1,**options))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation d'un object KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 1.3953 - val_loss: 16.5776\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.7548 - val_loss: 6.2139\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.5620 - val_loss: 0.5822\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4891 - val_loss: 0.4882\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4591 - val_loss: 0.4207\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4434 - val_loss: 0.4343\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4337 - val_loss: 0.4086\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4261 - val_loss: 0.4406\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4203 - val_loss: 0.4101\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4191 - val_loss: 0.4342\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4150 - val_loss: 0.4015\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4116 - val_loss: 0.4528\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4105 - val_loss: 0.3895\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.4082 - val_loss: 0.4139\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4058 - val_loss: 0.4020\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4034 - val_loss: 0.4678\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4013 - val_loss: 0.3796\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4005 - val_loss: 0.4585\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3992 - val_loss: 0.3721\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3975 - val_loss: 0.4370\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3953 - val_loss: 0.3915\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3938 - val_loss: 0.4592\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3923 - val_loss: 0.3801\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3900 - val_loss: 0.3762\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3888 - val_loss: 0.5403\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3887 - val_loss: 0.3637\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3862 - val_loss: 0.3731\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3856 - val_loss: 0.3598\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.3839 - val_loss: 0.4648\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3836 - val_loss: 0.3681\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3807 - val_loss: 0.5770\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3810 - val_loss: 0.3611\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3779 - val_loss: 0.5416\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3808 - val_loss: 0.3558\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3762 - val_loss: 0.5300\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3770 - val_loss: 0.4314\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3749 - val_loss: 0.3865\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3735 - val_loss: 0.3587\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3722 - val_loss: 0.3507\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.3727 - val_loss: 0.4737\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3717 - val_loss: 0.3612\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3694 - val_loss: 0.3643\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3687 - val_loss: 0.3672\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.3676 - val_loss: 0.3646\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3669 - val_loss: 0.3712\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.3660 - val_loss: 0.3569\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 0.3653 - val_loss: 0.4815\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3649 - val_loss: 0.5092\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3640 - val_loss: 0.8477\n",
      "5160/5160 [==============================] - 0s 15us/sample - loss: 0.3613\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "keras_reg.fit(X_train,y_train,epochs=100,\n",
    "             validation_data = (X_valid,y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "mse_test = keras_reg.score(X_test,y_test)\n",
    "#y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\":[0,1,2,3],\n",
    "    \"n_neurons\":np.arange(1,100),\n",
    "    \"learning_rate\":reciprocal(3e-4,3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 152us/sample - loss: 2.1091 - val_loss: 1.3747\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.9795 - val_loss: 1.0202\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.7911 - val_loss: 0.8236\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6850 - val_loss: 0.6780\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6208 - val_loss: 0.5999\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5818 - val_loss: 0.5444\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5549 - val_loss: 0.5121\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5353 - val_loss: 0.4920\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5212 - val_loss: 0.4758\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5099 - val_loss: 0.4657\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5004 - val_loss: 0.4579\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4930 - val_loss: 0.4518\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4861 - val_loss: 0.4466\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4805 - val_loss: 0.4414\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4750 - val_loss: 0.4369\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4703 - val_loss: 0.4331\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4657 - val_loss: 0.4297\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4618 - val_loss: 0.4261\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4579 - val_loss: 0.4229\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4544 - val_loss: 0.4199\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4511 - val_loss: 0.4180\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.4476 - val_loss: 0.4162\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4447 - val_loss: 0.4134\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4419 - val_loss: 0.4118\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4391 - val_loss: 0.4106\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4364 - val_loss: 0.4097\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4339 - val_loss: 0.4084\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4314 - val_loss: 0.4072\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4290 - val_loss: 0.4073\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4266 - val_loss: 0.4072\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4244 - val_loss: 0.4068\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4223 - val_loss: 0.4073\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4198 - val_loss: 0.4071\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4182 - val_loss: 0.4073\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4161 - val_loss: 0.4088\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4143 - val_loss: 0.4079\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4122 - val_loss: 0.4060\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4107 - val_loss: 0.4086\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4091 - val_loss: 0.4067\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4073 - val_loss: 0.4088\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4059 - val_loss: 0.4083\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4043 - val_loss: 0.4083\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.4027 - val_loss: 0.4093\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4013 - val_loss: 0.4074\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4001 - val_loss: 0.4085\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3985 - val_loss: 0.4071\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3975 - val_loss: 0.4089\n",
      "3870/3870 [==============================] - 0s 38us/sample - loss: 0.4206\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 148us/sample - loss: 3.5732 - val_loss: 2.9162\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 1.3632 - val_loss: 3.7096\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.0478 - val_loss: 3.1019\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.9705 - val_loss: 2.3982\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.9189 - val_loss: 1.8795\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8801 - val_loss: 1.4586\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.8480 - val_loss: 1.1893\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8205 - val_loss: 0.9812\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.7957 - val_loss: 0.8291\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7728 - val_loss: 0.7426\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7512 - val_loss: 0.7147\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7315 - val_loss: 0.6931\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7124 - val_loss: 0.6741\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6947 - val_loss: 0.6558\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6783 - val_loss: 0.6374\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6631 - val_loss: 0.6210\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6487 - val_loss: 0.6060\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6350 - val_loss: 0.5928\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6225 - val_loss: 0.5804\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6103 - val_loss: 0.5689\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5989 - val_loss: 0.5601\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5883 - val_loss: 0.5512\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5787 - val_loss: 0.5434\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5694 - val_loss: 0.5365\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5607 - val_loss: 0.5302\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5524 - val_loss: 0.5243\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5446 - val_loss: 0.5188\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5371 - val_loss: 0.5138\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5297 - val_loss: 0.5091\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5228 - val_loss: 0.5046\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5161 - val_loss: 0.5002\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5097 - val_loss: 0.4959\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5037 - val_loss: 0.4914\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4979 - val_loss: 0.4873\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4924 - val_loss: 0.4828\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4871 - val_loss: 0.4789\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4820 - val_loss: 0.4746\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4770 - val_loss: 0.4712\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4724 - val_loss: 0.4663\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4680 - val_loss: 0.4626\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4637 - val_loss: 0.4591\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4598 - val_loss: 0.4556\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4562 - val_loss: 0.4522\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4526 - val_loss: 0.4491\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4492 - val_loss: 0.4462\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.4459 - val_loss: 0.4436\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4430 - val_loss: 0.4407\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4404 - val_loss: 0.4382\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4376 - val_loss: 0.4356\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4352 - val_loss: 0.4333\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4327 - val_loss: 0.4316\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4305 - val_loss: 0.4292\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4284 - val_loss: 0.4276\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4262 - val_loss: 0.4249\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4244 - val_loss: 0.4224\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4224 - val_loss: 0.4202\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4206 - val_loss: 0.4184\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4191 - val_loss: 0.4164\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4173 - val_loss: 0.4145\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4161 - val_loss: 0.4127\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4144 - val_loss: 0.4110\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.4130 - val_loss: 0.4096\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4116 - val_loss: 0.4081\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4100 - val_loss: 0.4068\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4087 - val_loss: 0.4059\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4075 - val_loss: 0.4047\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4059 - val_loss: 0.4039\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4047 - val_loss: 0.4034\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4036 - val_loss: 0.4021\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4024 - val_loss: 0.4013\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.4011 - val_loss: 0.4006\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.4000 - val_loss: 0.3999\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3989 - val_loss: 0.3994\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3979 - val_loss: 0.3991\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3969 - val_loss: 0.3989\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3957 - val_loss: 0.3987\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3947 - val_loss: 0.3988\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3935 - val_loss: 0.3989\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3926 - val_loss: 0.3990\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3916 - val_loss: 0.3988\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3906 - val_loss: 0.3991\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.3896 - val_loss: 0.3991\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3885 - val_loss: 0.4000\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3875 - val_loss: 0.4003\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.3867 - val_loss: 0.4007\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.3858 - val_loss: 0.4009\n",
      "3870/3870 [==============================] - 0s 20us/sample - loss: 0.4081\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 144us/sample - loss: 4.2052 - val_loss: 5.7168\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 1.8515 - val_loss: 2.6113\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 1.2466 - val_loss: 1.1561\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 1.0584 - val_loss: 1.0151\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.9612 - val_loss: 0.9267\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.8860 - val_loss: 0.8499\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.8259 - val_loss: 0.8212\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.7776 - val_loss: 0.7495\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.7392 - val_loss: 0.7104\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.7085 - val_loss: 0.6900\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.6845 - val_loss: 0.6763\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6646 - val_loss: 0.6973\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.6480 - val_loss: 0.6902\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6337 - val_loss: 0.6912\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6210 - val_loss: 0.6864\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6101 - val_loss: 0.6484\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5992 - val_loss: 0.6713\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.5898 - val_loss: 0.6135\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5805 - val_loss: 0.6281\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5718 - val_loss: 0.5901\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5635 - val_loss: 0.5707\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5555 - val_loss: 0.5600\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5485 - val_loss: 0.5638\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5417 - val_loss: 0.5775\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5352 - val_loss: 0.5875\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5294 - val_loss: 0.5609\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5236 - val_loss: 0.5576\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5182 - val_loss: 0.5413\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5124 - val_loss: 0.5222\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5069 - val_loss: 0.5179\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5020 - val_loss: 0.5038\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4967 - val_loss: 0.4956\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4920 - val_loss: 0.4807\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4877 - val_loss: 0.4776\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4835 - val_loss: 0.4683\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4794 - val_loss: 0.4618\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4754 - val_loss: 0.4545\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.4719 - val_loss: 0.4484\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4684 - val_loss: 0.4423\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4652 - val_loss: 0.4415\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4619 - val_loss: 0.4364\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4587 - val_loss: 0.4329\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4556 - val_loss: 0.4276\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4526 - val_loss: 0.4255\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4493 - val_loss: 0.4214\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4467 - val_loss: 0.4183\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4439 - val_loss: 0.4155\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4411 - val_loss: 0.4131\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4385 - val_loss: 0.4098\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4357 - val_loss: 0.4072\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4329 - val_loss: 0.4045\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4308 - val_loss: 0.4024\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4284 - val_loss: 0.4007\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4260 - val_loss: 0.3986\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4239 - val_loss: 0.3962\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.4220 - val_loss: 0.3940\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4198 - val_loss: 0.3923\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4175 - val_loss: 0.3945\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4158 - val_loss: 0.3888\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4143 - val_loss: 0.3877\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4126 - val_loss: 0.3868\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4111 - val_loss: 0.3884\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4099 - val_loss: 0.3832\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4084 - val_loss: 0.3826\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4073 - val_loss: 0.3802\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4059 - val_loss: 0.3794\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.4046 - val_loss: 0.3819\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.4035 - val_loss: 0.3844\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.4025 - val_loss: 0.3800\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.4011 - val_loss: 0.3770\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.3999 - val_loss: 0.3753\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3991 - val_loss: 0.3740\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3982 - val_loss: 0.3761\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3971 - val_loss: 0.3706\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3962 - val_loss: 0.3695\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3949 - val_loss: 0.3734\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3942 - val_loss: 0.3688\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3934 - val_loss: 0.3683\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3925 - val_loss: 0.3693\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3917 - val_loss: 0.3679\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3908 - val_loss: 0.3669\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3899 - val_loss: 0.3653\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3890 - val_loss: 0.3649\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.3882 - val_loss: 0.3627\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3875 - val_loss: 0.3638\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3870 - val_loss: 0.3659\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3861 - val_loss: 0.3628\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3855 - val_loss: 0.3627\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3845 - val_loss: 0.3595\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3842 - val_loss: 0.3589\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.3833 - val_loss: 0.3613\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3828 - val_loss: 0.3598\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3820 - val_loss: 0.3608\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3814 - val_loss: 0.3578\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.3810 - val_loss: 0.3576\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.3804 - val_loss: 0.3566\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3797 - val_loss: 0.3559\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.3789 - val_loss: 0.3568\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.3787 - val_loss: 0.3550\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.3781 - val_loss: 0.3552\n",
      "3870/3870 [==============================] - 0s 25us/sample - loss: 0.3830\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 141us/sample - loss: 6.9221 - val_loss: 6.9367\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 4.1631 - val_loss: 3.9969\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 2.6580 - val_loss: 2.5435\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.8240 - val_loss: 1.7585\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 1.3537 - val_loss: 1.3373\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 1.0845 - val_loss: 1.1204\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.9276 - val_loss: 0.9954\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.8343 - val_loss: 0.9146\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7760 - val_loss: 0.9336\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.7396 - val_loss: 0.8979\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7147 - val_loss: 0.8618\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6967 - val_loss: 0.8997\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.6839 - val_loss: 0.8681\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6733 - val_loss: 0.8809\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6644 - val_loss: 0.9121\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6572 - val_loss: 0.8915\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6502 - val_loss: 0.9235\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6440 - val_loss: 0.9636\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6390 - val_loss: 0.9010\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6336 - val_loss: 0.8582\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6286 - val_loss: 0.8439\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6239 - val_loss: 0.8327\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6190 - val_loss: 0.8833\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6151 - val_loss: 0.9025\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6114 - val_loss: 0.8627\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6075 - val_loss: 0.8595\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6037 - val_loss: 0.8785\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.6003 - val_loss: 0.8759\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5966 - val_loss: 0.9225\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5940 - val_loss: 0.8521\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5909 - val_loss: 0.8474\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5879 - val_loss: 0.8394\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5882\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 139us/sample - loss: 5.4873 - val_loss: 40.9781\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 3.0340 - val_loss: 39.8345\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 1.8449 - val_loss: 39.0614\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 1.2485 - val_loss: 38.3832\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.9418 - val_loss: 37.7082\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.7801 - val_loss: 37.0576\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6927 - val_loss: 36.3977\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6442 - val_loss: 35.7526\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6164 - val_loss: 35.1139\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5997 - val_loss: 34.4972\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5889 - val_loss: 33.8927\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5815 - val_loss: 33.2940\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5759 - val_loss: 32.7510\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5715 - val_loss: 32.2118\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5676 - val_loss: 31.6982\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5643 - val_loss: 31.2132\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5612 - val_loss: 30.7726\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5584 - val_loss: 30.3480\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5556 - val_loss: 29.9240\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5531 - val_loss: 29.5588\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5507 - val_loss: 29.1702\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5484 - val_loss: 28.8286\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5462 - val_loss: 28.4973\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5441 - val_loss: 28.1674\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5421 - val_loss: 27.8589\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5402 - val_loss: 27.5831\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5384 - val_loss: 27.3134\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5366 - val_loss: 27.0704\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5349 - val_loss: 26.8250\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5334 - val_loss: 26.5959\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5318 - val_loss: 26.3718\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5304 - val_loss: 26.1611\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5290 - val_loss: 25.9316\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5277 - val_loss: 25.7349\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5264 - val_loss: 25.5353\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5252 - val_loss: 25.3529\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5240 - val_loss: 25.1763\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5229 - val_loss: 24.9901\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5219 - val_loss: 24.8280\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5208 - val_loss: 24.6816\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5198 - val_loss: 24.5420\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5189 - val_loss: 24.3883\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5180 - val_loss: 24.2425\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5172 - val_loss: 24.1026\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5164 - val_loss: 23.9698\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5156 - val_loss: 23.8533\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5148 - val_loss: 23.7175\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5141 - val_loss: 23.6121\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5134 - val_loss: 23.4923\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5128 - val_loss: 23.3982\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5122 - val_loss: 23.2851\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5116 - val_loss: 23.1936\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5110 - val_loss: 23.1154\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5104 - val_loss: 23.0263\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5099 - val_loss: 22.9330\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5094 - val_loss: 22.8469\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5089 - val_loss: 22.7704\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5085 - val_loss: 22.7037\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5081 - val_loss: 22.6161\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5076 - val_loss: 22.5638\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5072 - val_loss: 22.4876\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5068 - val_loss: 22.4054\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5064 - val_loss: 22.3526\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5061 - val_loss: 22.2840\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5057 - val_loss: 22.2139\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5054 - val_loss: 22.1358\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5051 - val_loss: 22.0736\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5048 - val_loss: 22.0240\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5045 - val_loss: 21.9981\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5042 - val_loss: 21.9506\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5040 - val_loss: 21.9078\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5037 - val_loss: 21.8795\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5035 - val_loss: 21.8318\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5033 - val_loss: 21.7801\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5030 - val_loss: 21.7491\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5028 - val_loss: 21.6945\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5026 - val_loss: 21.6592\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5024 - val_loss: 21.6236\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5022 - val_loss: 21.5755\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5020 - val_loss: 21.5297\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5018 - val_loss: 21.5007\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5016 - val_loss: 21.4860\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5015 - val_loss: 21.4502\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5014 - val_loss: 21.4225\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5012 - val_loss: 21.3841\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5011 - val_loss: 21.3438\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5009 - val_loss: 21.3205\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5008 - val_loss: 21.2956\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5007 - val_loss: 21.2532\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5006 - val_loss: 21.2427\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5004 - val_loss: 21.2189\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5003 - val_loss: 21.1923\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5002 - val_loss: 21.1898\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5001 - val_loss: 21.1709\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5000 - val_loss: 21.1335\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.4999 - val_loss: 21.1074\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.4998 - val_loss: 21.1067\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4998 - val_loss: 21.0837\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.4997 - val_loss: 21.0724\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.4996 - val_loss: 21.0651\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 1.0062\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 156us/sample - loss: 5.8502 - val_loss: 9.0566\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 3.3379 - val_loss: 5.0355\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 2.0318 - val_loss: 2.9911\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.3437 - val_loss: 2.0321\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.9786 - val_loss: 1.4950\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7830 - val_loss: 1.1619\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.6770 - val_loss: 1.0870\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.6206 - val_loss: 0.9806\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5890 - val_loss: 0.9183\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5713 - val_loss: 0.8411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5605 - val_loss: 0.8469\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5547 - val_loss: 0.7853\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5508 - val_loss: 0.7408\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5481 - val_loss: 0.7570\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5460 - val_loss: 0.8012\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 34us/sample - loss: 0.5450 - val_loss: 0.7883\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5436 - val_loss: 0.8105\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5427 - val_loss: 0.8209\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5421 - val_loss: 0.8068\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5416 - val_loss: 0.7579\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 35us/sample - loss: 0.5403 - val_loss: 0.7807\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5399 - val_loss: 0.7834\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5391 - val_loss: 0.7968\n",
      "3870/3870 [==============================] - 0s 18us/sample - loss: 0.5460\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 168us/sample - loss: 2.9434 - val_loss: 1.4816\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 1.1057 - val_loss: 0.8135\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7909 - val_loss: 1.0996\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.7207 - val_loss: 1.0769\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6926 - val_loss: 0.6308\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6659 - val_loss: 0.6129\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6468 - val_loss: 0.6526\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6272 - val_loss: 1.0334\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6227 - val_loss: 0.5678\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6030 - val_loss: 0.8256\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5958 - val_loss: 0.8204\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5869 - val_loss: 0.8137\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5812 - val_loss: 0.5846\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5728 - val_loss: 0.5284\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5658 - val_loss: 0.5758\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5619 - val_loss: 0.5206\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5569 - val_loss: 0.5267\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5507 - val_loss: 0.7396\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5504 - val_loss: 0.7053\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5492 - val_loss: 0.5135\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5425 - val_loss: 0.6865\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5447 - val_loss: 0.5035\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5364 - val_loss: 0.8710\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5425 - val_loss: 0.5903\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5389 - val_loss: 0.5060\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5356 - val_loss: 0.5775\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5329 - val_loss: 0.7901\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5379 - val_loss: 0.5055\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 36us/sample - loss: 0.5338 - val_loss: 0.5034\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5305 - val_loss: 0.7126\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5338 - val_loss: 0.5902\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5314 - val_loss: 0.6416\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5309 - val_loss: 0.7080\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5325 - val_loss: 0.5850\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5284 - val_loss: 0.7790\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5297 - val_loss: 0.8245\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5339 - val_loss: 0.4983\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5298 - val_loss: 0.4973\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5268 - val_loss: 0.7410\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5330 - val_loss: 0.4953\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5289 - val_loss: 0.5168\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5299 - val_loss: 0.4923\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5240 - val_loss: 0.9295\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5346 - val_loss: 0.5004\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5292 - val_loss: 0.4919\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5234 - val_loss: 0.9206\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5339 - val_loss: 0.5040\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5259 - val_loss: 0.7392\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5312 - val_loss: 0.5386\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5260 - val_loss: 0.7644\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5303 - val_loss: 0.6424\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5307 - val_loss: 0.4953\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5235 - val_loss: 0.9244\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5317 - val_loss: 0.7097\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5301 - val_loss: 0.5780\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.5357\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 152us/sample - loss: 3.7811 - val_loss: 2.4213\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 1.1526 - val_loss: 0.7741\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.7273 - val_loss: 1.3731\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.6353 - val_loss: 2.8938\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6013 - val_loss: 4.9032\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5814 - val_loss: 6.8886\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5668 - val_loss: 9.0363\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5554 - val_loss: 10.9216\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5463 - val_loss: 12.6602\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5387 - val_loss: 14.2875\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5326 - val_loss: 15.6633\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5275 - val_loss: 16.7936\n",
      "3870/3870 [==============================] - 0s 22us/sample - loss: 0.9188\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 1s 154us/sample - loss: 3.7497 - val_loss: 2.2517\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 1.0867 - val_loss: 0.8971\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.7418 - val_loss: 0.7644\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.6720 - val_loss: 0.6199\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.6453 - val_loss: 0.5922\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6276 - val_loss: 0.7404\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6136 - val_loss: 0.9745\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.6043 - val_loss: 0.9856\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.6008 - val_loss: 0.5493\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5849 - val_loss: 0.8644\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5834 - val_loss: 0.6380\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5753 - val_loss: 0.6059\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5661 - val_loss: 0.8153\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5669 - val_loss: 0.5224\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5597 - val_loss: 0.5175\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5563 - val_loss: 0.5765\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5498 - val_loss: 0.8992\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5545 - val_loss: 0.6144\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5489 - val_loss: 0.6186\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5472 - val_loss: 0.5691\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5448 - val_loss: 0.5098\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5415 - val_loss: 0.6190\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5422 - val_loss: 0.6026\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5381 - val_loss: 0.7856\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 38us/sample - loss: 0.5407 - val_loss: 0.5850\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.5394 - val_loss: 0.5310\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.540 - 0s 45us/sample - loss: 0.5380 - val_loss: 0.5325\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 37us/sample - loss: 0.5373 - val_loss: 0.5098\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5350 - val_loss: 0.5419\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5369 - val_loss: 0.4948\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 39us/sample - loss: 0.5314 - val_loss: 0.8362\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 43us/sample - loss: 0.5383 - val_loss: 0.4948\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 41us/sample - loss: 0.5316 - val_loss: 0.7450\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5358 - val_loss: 0.5545\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5343 - val_loss: 0.5551\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 42us/sample - loss: 0.5307 - val_loss: 0.7597\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5344 - val_loss: 0.6533\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 40us/sample - loss: 0.5319 - val_loss: 0.7422\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 0.5319 - val_loss: 0.7040\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5338 - val_loss: 0.5511\n",
      "3870/3870 [==============================] - 0s 21us/sample - loss: 0.5322\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 234us/sample - loss: 1.2913 - val_loss: 2.5290\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.6004 - val_loss: 0.5543\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4805 - val_loss: 0.4503\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4310 - val_loss: 0.4108\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.4038 - val_loss: 0.4060\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3873 - val_loss: 0.4207\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.3765 - val_loss: 0.4118\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.3698 - val_loss: 0.4038\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.3633 - val_loss: 0.4051\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3604 - val_loss: 0.3832\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3542 - val_loss: 0.3902\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.3508 - val_loss: 0.3699\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.3485 - val_loss: 0.3812\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.3439 - val_loss: 0.3559\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.3413 - val_loss: 0.3552\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 2s 206us/sample - loss: 0.3387 - val_loss: 0.3534\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3358 - val_loss: 0.3767\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 118us/sample - loss: 0.3342 - val_loss: 0.3527\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 2s 194us/sample - loss: 0.3317 - val_loss: 0.3484\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 192us/sample - loss: 0.3306 - val_loss: 0.3691\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 170us/sample - loss: 0.3284 - val_loss: 0.3574\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 178us/sample - loss: 0.3241 - val_loss: 0.3371\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 175us/sample - loss: 0.3238 - val_loss: 0.3698\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 116us/sample - loss: 0.3227 - val_loss: 0.3341\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 122us/sample - loss: 0.3210 - val_loss: 0.3340\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3182 - val_loss: 0.3334\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3170 - val_loss: 0.3447\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 0.3158 - val_loss: 0.3769\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.3137 - val_loss: 0.3691\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 0.3124 - val_loss: 0.3568\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 0.3110 - val_loss: 0.3661\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.3094 - val_loss: 0.3611\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.3096 - val_loss: 0.3457\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.3074 - val_loss: 0.3049\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.3055 - val_loss: 0.3147\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3049 - val_loss: 0.3113\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.3034 - val_loss: 0.3044\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.3018 - val_loss: 0.3348\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3022 - val_loss: 0.3947\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3063 - val_loss: 0.3643\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.2996 - val_loss: 0.3552\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 0.2994 - val_loss: 0.2958\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.2959 - val_loss: 0.3435\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.2941 - val_loss: 0.3689\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.2946 - val_loss: 0.2983\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.2932 - val_loss: 0.3217\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.2925 - val_loss: 0.3168\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.2916 - val_loss: 0.2926\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.2909 - val_loss: 0.3371\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.2884 - val_loss: 0.3463\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.2874 - val_loss: 0.2898\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.2870 - val_loss: 0.3060\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.2851 - val_loss: 0.2978\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.2860 - val_loss: 0.2983\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.2838 - val_loss: 0.2987\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 0.2825 - val_loss: 0.3329\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.2855 - val_loss: 0.2867\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 96us/sample - loss: 0.2848 - val_loss: 0.3203\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 96us/sample - loss: 0.2855 - val_loss: 0.2863\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.2796 - val_loss: 0.3514\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.2789 - val_loss: 0.3921\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.2781 - val_loss: 0.3220\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.2773 - val_loss: 0.3965\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.2767 - val_loss: 0.2964\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 0.2761 - val_loss: 0.4181\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 96us/sample - loss: 0.2754 - val_loss: 0.2860\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.2733 - val_loss: 0.3102\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 0.2733 - val_loss: 0.3635\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.2727 - val_loss: 0.2786\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.2719 - val_loss: 0.2905\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.2712 - val_loss: 0.4045\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.2714 - val_loss: 0.4687\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.2716 - val_loss: 0.4905\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.2704 - val_loss: 0.3396\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 90us/sample - loss: 0.2706 - val_loss: 0.4844\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 0.2688 - val_loss: 0.3125\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 117us/sample - loss: 0.2688 - val_loss: 0.4321\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 113us/sample - loss: 0.2681 - val_loss: 0.2928\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 122us/sample - loss: 0.2664 - val_loss: 0.3113\n",
      "3870/3870 [==============================] - 0s 53us/sample - loss: 0.3154\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 309us/sample - loss: 1.1601 - val_loss: 0.5887\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 0.5374 - val_loss: 1.6169\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 110us/sample - loss: 0.4718 - val_loss: 1.2999\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4336 - val_loss: 1.1808\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 118us/sample - loss: 0.4114 - val_loss: 0.5170\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 103us/sample - loss: 0.3930 - val_loss: 0.4825\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 112us/sample - loss: 0.3818 - val_loss: 0.3688\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 110us/sample - loss: 0.3708 - val_loss: 0.4225\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 0.3614 - val_loss: 0.3871\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 0.3543 - val_loss: 0.6368\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3506 - val_loss: 0.5181\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.3447 - val_loss: 0.6510\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 132us/sample - loss: 0.3404 - val_loss: 0.5787\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3391 - val_loss: 0.5404\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 146us/sample - loss: 0.3361 - val_loss: 0.4084\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 123us/sample - loss: 0.3327 - val_loss: 0.4710\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 136us/sample - loss: 0.3303 - val_loss: 0.4866\n",
      "3870/3870 [==============================] - 0s 46us/sample - loss: 0.3513\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 3s 328us/sample - loss: 1.3328 - val_loss: 1.8771\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 117us/sample - loss: 0.5406 - val_loss: 4.9260\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.5145 - val_loss: 1.7084\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 0.4384 - val_loss: 0.4064\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 130us/sample - loss: 0.4063 - val_loss: 0.4018\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 140us/sample - loss: 0.3935 - val_loss: 0.4404\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 115us/sample - loss: 0.3861 - val_loss: 0.3912\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.3791 - val_loss: 0.4055\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 121us/sample - loss: 0.3736 - val_loss: 0.4067\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.3683 - val_loss: 0.3572\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 119us/sample - loss: 0.3637 - val_loss: 0.4005\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.3604 - val_loss: 0.3870\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3553 - val_loss: 0.3573\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 109us/sample - loss: 0.3519 - val_loss: 0.3593\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.3502 - val_loss: 0.3739\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 126us/sample - loss: 0.3463 - val_loss: 0.3694\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 113us/sample - loss: 0.3437 - val_loss: 0.3728\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 106us/sample - loss: 0.3406 - val_loss: 0.4289\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 135us/sample - loss: 0.3392 - val_loss: 0.3487\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 121us/sample - loss: 0.3365 - val_loss: 0.3421\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 0.3340 - val_loss: 0.3178\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.3309 - val_loss: 0.3740\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 132us/sample - loss: 0.3301 - val_loss: 0.3174\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 121us/sample - loss: 0.3277 - val_loss: 0.3112\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 135us/sample - loss: 0.3257 - val_loss: 0.3138\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 130us/sample - loss: 0.3229 - val_loss: 0.3320\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 143us/sample - loss: 0.3202 - val_loss: 0.3862\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 139us/sample - loss: 0.3186 - val_loss: 0.3156\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 147us/sample - loss: 0.3172 - val_loss: 0.3523\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 132us/sample - loss: 0.3158 - val_loss: 0.3272\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 141us/sample - loss: 0.3141 - val_loss: 0.3687\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 104us/sample - loss: 0.3120 - val_loss: 0.3472\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3109 - val_loss: 0.3091\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.3100 - val_loss: 0.3226\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.3079 - val_loss: 0.3302\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.3073 - val_loss: 0.3632\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3056 - val_loss: 0.3221\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.3036 - val_loss: 0.3168\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 130us/sample - loss: 0.3024 - val_loss: 0.3232\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 85us/sample - loss: 0.3017 - val_loss: 0.3059\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3001 - val_loss: 0.3235\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 107us/sample - loss: 0.2991 - val_loss: 0.4276\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 90us/sample - loss: 0.2982 - val_loss: 0.2952\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 0.2966 - val_loss: 0.3232\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 104us/sample - loss: 0.2963 - val_loss: 0.3150\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.2965 - val_loss: 0.3554\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 0.2938 - val_loss: 0.2993\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 115us/sample - loss: 0.2929 - val_loss: 0.3188\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 104us/sample - loss: 0.2919 - val_loss: 0.3377\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 103us/sample - loss: 0.2902 - val_loss: 0.2941\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 96us/sample - loss: 0.2904 - val_loss: 0.2886\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 107us/sample - loss: 0.2880 - val_loss: 0.3425\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.2885 - val_loss: 0.3547\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.2889 - val_loss: 0.4893\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 125us/sample - loss: 0.2879 - val_loss: 0.3009\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.2853 - val_loss: 0.2991\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 0.2857 - val_loss: 0.3032\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.2843 - val_loss: 0.3133\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 78us/sample - loss: 0.2839 - val_loss: 0.2873\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 99us/sample - loss: 0.2816 - val_loss: 0.3260\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.2826 - val_loss: 0.3193\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 107us/sample - loss: 0.2823 - val_loss: 0.4380\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.2829 - val_loss: 0.3835\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.2819 - val_loss: 0.4590\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 0.2815 - val_loss: 0.3079\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 98us/sample - loss: 0.2789 - val_loss: 0.4268\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.2806 - val_loss: 0.3052\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.2780 - val_loss: 0.3439\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 112us/sample - loss: 0.2776 - val_loss: 0.2808\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 110us/sample - loss: 0.2759 - val_loss: 0.2953\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 118us/sample - loss: 0.2745 - val_loss: 0.2813\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 110us/sample - loss: 0.2752 - val_loss: 0.3066\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 1s 127us/sample - loss: 0.2749 - val_loss: 0.2860\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 1s 117us/sample - loss: 0.2729 - val_loss: 0.2807\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 125us/sample - loss: 0.2734 - val_loss: 0.2990\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 111us/sample - loss: 0.2723 - val_loss: 0.3127\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 1s 112us/sample - loss: 0.2724 - val_loss: 0.2757\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.2709 - val_loss: 0.2928\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 1s 102us/sample - loss: 0.2704 - val_loss: 0.2886\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 97us/sample - loss: 0.2703 - val_loss: 0.2807\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 103us/sample - loss: 0.2698 - val_loss: 0.3532\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 101us/sample - loss: 0.2689 - val_loss: 0.2959\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 112us/sample - loss: 0.2699 - val_loss: 0.3338\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 93us/sample - loss: 0.2694 - val_loss: 0.2980\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 102us/sample - loss: 0.2673 - val_loss: 0.2914\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.2675 - val_loss: 0.2791\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 94us/sample - loss: 0.2664 - val_loss: 0.2848\n",
      "3870/3870 [==============================] - 0s 35us/sample - loss: 0.2922\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 230us/sample - loss: 4.2895 - val_loss: 6.2736\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 2.3241 - val_loss: 5.1877\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 1.5587 - val_loss: 3.2238\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 1.1902 - val_loss: 2.0433\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.9993 - val_loss: 1.3957\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.8964 - val_loss: 1.0489\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.8356 - val_loss: 0.8678\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7964 - val_loss: 0.7783\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7685 - val_loss: 0.7289\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.7468 - val_loss: 0.7047\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.7289 - val_loss: 0.6908\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.7134 - val_loss: 0.6768\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6996 - val_loss: 0.6653\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.6868 - val_loss: 0.6614\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6751 - val_loss: 0.6533\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.6642 - val_loss: 0.6403\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.6537 - val_loss: 0.6321\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6437 - val_loss: 0.6272\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6342 - val_loss: 0.6204\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6252 - val_loss: 0.6128\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6165 - val_loss: 0.6066\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.6082 - val_loss: 0.5972\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 46us/sample - loss: 0.6002 - val_loss: 0.5937\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5926 - val_loss: 0.5791\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5851 - val_loss: 0.5739\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5781 - val_loss: 0.5628\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5712 - val_loss: 0.5539\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5646 - val_loss: 0.5484\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 0.5583 - val_loss: 0.5402\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5522 - val_loss: 0.5312\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5463 - val_loss: 0.5266\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 45us/sample - loss: 0.5406 - val_loss: 0.5194\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 0.5351 - val_loss: 0.5174\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5300 - val_loss: 0.5118\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.5249 - val_loss: 0.5054\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5200 - val_loss: 0.4977\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5153 - val_loss: 0.4918\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.5108 - val_loss: 0.4895\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5065 - val_loss: 0.4831\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.5024 - val_loss: 0.4792\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4983 - val_loss: 0.4765\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4946 - val_loss: 0.4722\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4909 - val_loss: 0.4688\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4874 - val_loss: 0.4641\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4840 - val_loss: 0.4605\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4807 - val_loss: 0.4555\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4776 - val_loss: 0.4524\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4746 - val_loss: 0.4498\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4717 - val_loss: 0.4465\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4689 - val_loss: 0.4440\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4663 - val_loss: 0.4412\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4637 - val_loss: 0.4391\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4613 - val_loss: 0.4363\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4589 - val_loss: 0.4338\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4567 - val_loss: 0.4316\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4544 - val_loss: 0.4294\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4524 - val_loss: 0.4275\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4503 - val_loss: 0.4255\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4484 - val_loss: 0.4236\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4465 - val_loss: 0.4221\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4448 - val_loss: 0.4204\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4432 - val_loss: 0.4186\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4415 - val_loss: 0.4171\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4399 - val_loss: 0.4154\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4385 - val_loss: 0.4144\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4370 - val_loss: 0.4131\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4356 - val_loss: 0.4121\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4343 - val_loss: 0.4107\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4329 - val_loss: 0.4093\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4316 - val_loss: 0.4089\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4305 - val_loss: 0.4077\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4293 - val_loss: 0.4067\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4281 - val_loss: 0.4057\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4270 - val_loss: 0.4050\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4259 - val_loss: 0.4037\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4249 - val_loss: 0.4036\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4238 - val_loss: 0.4032\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4228 - val_loss: 0.4023\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4219 - val_loss: 0.4015\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4209 - val_loss: 0.4003\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4200 - val_loss: 0.3991\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4191 - val_loss: 0.3981\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4183 - val_loss: 0.3978\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4174 - val_loss: 0.3972\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4166 - val_loss: 0.3973\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4158 - val_loss: 0.3965\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4150 - val_loss: 0.3964\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4142 - val_loss: 0.3960\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4134 - val_loss: 0.3947\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4127 - val_loss: 0.3938\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4119 - val_loss: 0.3947\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4112 - val_loss: 0.3943\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4105 - val_loss: 0.3938\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4098 - val_loss: 0.3933\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4091 - val_loss: 0.3940\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4085 - val_loss: 0.3938\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.4078 - val_loss: 0.3955\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4072 - val_loss: 0.3945\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4066 - val_loss: 0.3924\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4059 - val_loss: 0.3929\n",
      "3870/3870 [==============================] - 0s 27us/sample - loss: 0.4148\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 221us/sample - loss: 4.0433 - val_loss: 2.5363\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 1.8809 - val_loss: 2.4697\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.2051 - val_loss: 2.5649\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.9632 - val_loss: 2.3112\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.8617 - val_loss: 1.9064\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.8103 - val_loss: 1.5122\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7792 - val_loss: 1.2095\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7570 - val_loss: 0.9812\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7393 - val_loss: 0.8260\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7242 - val_loss: 0.7293\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7106 - val_loss: 0.6767\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6981 - val_loss: 0.6642\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6864 - val_loss: 0.6798\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6753 - val_loss: 0.7170\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6647 - val_loss: 0.7735\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6546 - val_loss: 0.8408\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6451 - val_loss: 0.9266\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6359 - val_loss: 1.0144\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6270 - val_loss: 1.0946\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6185 - val_loss: 1.1822\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6104 - val_loss: 1.2756\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6026 - val_loss: 1.3749\n",
      "3870/3870 [==============================] - 0s 31us/sample - loss: 0.6252\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 222us/sample - loss: 4.2303 - val_loss: 4.5606\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 2.1268 - val_loss: 3.6608\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 1.3305 - val_loss: 2.2656\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.9970 - val_loss: 1.3099\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.8516 - val_loss: 0.8963\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7844 - val_loss: 0.7574\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7490 - val_loss: 0.7088\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.7268 - val_loss: 0.6923\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.7105 - val_loss: 0.6861\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6974 - val_loss: 0.6772\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6858 - val_loss: 0.6655\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6752 - val_loss: 0.6547\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.6651 - val_loss: 0.6595\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6562 - val_loss: 0.6427\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6473 - val_loss: 0.6259\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6388 - val_loss: 0.6174\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6305 - val_loss: 0.6235\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6230 - val_loss: 0.6037\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6154 - val_loss: 0.6055\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6083 - val_loss: 0.5964\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6013 - val_loss: 0.5837\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5944 - val_loss: 0.5890\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5880 - val_loss: 0.5837\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5817 - val_loss: 0.5745\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5757 - val_loss: 0.5566\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5696 - val_loss: 0.5519\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5639 - val_loss: 0.5460\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5584 - val_loss: 0.5405\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5530 - val_loss: 0.5349\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5477 - val_loss: 0.5351\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5428 - val_loss: 0.5235\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5378 - val_loss: 0.5238\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5332 - val_loss: 0.5127\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5287 - val_loss: 0.5132\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 0.5243 - val_loss: 0.5070\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5200 - val_loss: 0.5088\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5161 - val_loss: 0.4959\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5121 - val_loss: 0.4984\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5084 - val_loss: 0.4894\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5048 - val_loss: 0.4877\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5013 - val_loss: 0.4801\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4978 - val_loss: 0.4821\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4947 - val_loss: 0.4780\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4915 - val_loss: 0.4763\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4885 - val_loss: 0.4750\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4856 - val_loss: 0.4682\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4827 - val_loss: 0.4607\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4800 - val_loss: 0.4590\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4774 - val_loss: 0.4552\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.4747 - val_loss: 0.4514\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4724 - val_loss: 0.4492\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4700 - val_loss: 0.4483\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4677 - val_loss: 0.4471\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4656 - val_loss: 0.4456\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4635 - val_loss: 0.4399\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4614 - val_loss: 0.4363\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4594 - val_loss: 0.4358\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.4574 - val_loss: 0.4359\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4556 - val_loss: 0.4330\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4538 - val_loss: 0.4298\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4520 - val_loss: 0.4297\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4504 - val_loss: 0.4271\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4487 - val_loss: 0.4255\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4472 - val_loss: 0.4221\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4456 - val_loss: 0.4222\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4442 - val_loss: 0.4202\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4428 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4414 - val_loss: 0.4163\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4401 - val_loss: 0.4155\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4388 - val_loss: 0.4137\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4376 - val_loss: 0.4123\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4364 - val_loss: 0.4104\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4352 - val_loss: 0.4086\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4340 - val_loss: 0.4074\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4329 - val_loss: 0.4066\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4318 - val_loss: 0.4054\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4308 - val_loss: 0.4044\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4297 - val_loss: 0.4027\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4287 - val_loss: 0.4020\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4277 - val_loss: 0.4016\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4268 - val_loss: 0.4004\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4258 - val_loss: 0.3989\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4249 - val_loss: 0.3981\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4241 - val_loss: 0.3973\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4231 - val_loss: 0.3967\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4223 - val_loss: 0.3959\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4214 - val_loss: 0.3949\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4206 - val_loss: 0.3944\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4198 - val_loss: 0.3935\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4191 - val_loss: 0.3927\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4183 - val_loss: 0.3920\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4176 - val_loss: 0.3916\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4169 - val_loss: 0.3908\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4162 - val_loss: 0.3901\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4155 - val_loss: 0.3894\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4148 - val_loss: 0.3887\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4142 - val_loss: 0.3882\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4135 - val_loss: 0.3876\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4129 - val_loss: 0.3870\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.4123 - val_loss: 0.3864\n",
      "3870/3870 [==============================] - 0s 35us/sample - loss: 0.4191\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 257us/sample - loss: 1.2272 - val_loss: 7.3753\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6169 - val_loss: 8.6450\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5320 - val_loss: 0.5843\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4185 - val_loss: 0.4042\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3910 - val_loss: 0.3818\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3786 - val_loss: 0.3718\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3686 - val_loss: 0.3735\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3629 - val_loss: 0.3671\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.3568 - val_loss: 0.3461\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3520 - val_loss: 0.3629\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.3500 - val_loss: 0.3483\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3465 - val_loss: 0.3461\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3439 - val_loss: 0.3655\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3406 - val_loss: 0.3384\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3388 - val_loss: 0.3488\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3362 - val_loss: 0.3393\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3343 - val_loss: 0.3408\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3326 - val_loss: 0.3879\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3308 - val_loss: 0.3379\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3297 - val_loss: 0.3355\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3280 - val_loss: 0.3651\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3268 - val_loss: 0.3595\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3252 - val_loss: 0.3646\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3237 - val_loss: 0.3606\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3215 - val_loss: 0.3216\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3209 - val_loss: 0.3779\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3196 - val_loss: 0.3150\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3188 - val_loss: 0.3607\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3177 - val_loss: 0.3771\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3161 - val_loss: 0.3148\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3145 - val_loss: 0.3631\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3144 - val_loss: 0.3673\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3130 - val_loss: 0.3699\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3114 - val_loss: 0.3125\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3107 - val_loss: 0.3678\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3089 - val_loss: 0.3479\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3086 - val_loss: 0.3730\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3075 - val_loss: 0.3162\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3061 - val_loss: 0.3373\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3043 - val_loss: 0.3642\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3027 - val_loss: 0.3522\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3026 - val_loss: 0.3370\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3018 - val_loss: 0.3002\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3010 - val_loss: 0.3624\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2993 - val_loss: 0.3695\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.2998 - val_loss: 0.3417\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2987 - val_loss: 0.3639\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2973 - val_loss: 0.4118\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.2977 - val_loss: 0.3616\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2983 - val_loss: 0.6165\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2990 - val_loss: 0.3570\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2965 - val_loss: 0.3262\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2933 - val_loss: 0.3262\n",
      "3870/3870 [==============================] - 0s 34us/sample - loss: 0.3280\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 262us/sample - loss: 1.1722 - val_loss: 1.2339\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5645 - val_loss: 0.5227\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4725 - val_loss: 0.4811\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4241 - val_loss: 0.4578\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4006 - val_loss: 0.3770\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3853 - val_loss: 0.3591\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3746 - val_loss: 0.3698\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3679 - val_loss: 0.4129\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.361 - 1s 78us/sample - loss: 0.3616 - val_loss: 0.4553\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3561 - val_loss: 0.5766\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3541 - val_loss: 0.5141\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3494 - val_loss: 0.4893\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.3455 - val_loss: 0.5697\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3436 - val_loss: 0.5380\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3415 - val_loss: 0.6052\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3383 - val_loss: 0.5629\n",
      "3870/3870 [==============================] - 0s 33us/sample - loss: 0.3549\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 279us/sample - loss: 1.1047 - val_loss: 0.7709\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.5381 - val_loss: 0.6372\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4728 - val_loss: 0.4159\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4352 - val_loss: 0.5178\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.4132 - val_loss: 0.4402\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3963 - val_loss: 0.5027\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3868 - val_loss: 0.3792\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3778 - val_loss: 0.4517\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3713 - val_loss: 0.4030\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3648 - val_loss: 0.3700\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3596 - val_loss: 0.5113\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3553 - val_loss: 0.4080\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3508 - val_loss: 0.3553\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3471 - val_loss: 0.3521\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3424 - val_loss: 0.4269\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.339 - 0s 62us/sample - loss: 0.3403 - val_loss: 0.3861\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3394 - val_loss: 0.4306\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3358 - val_loss: 0.3209\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3331 - val_loss: 0.3391\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3296 - val_loss: 0.4767\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3290 - val_loss: 0.3179\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3269 - val_loss: 0.3804\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3249 - val_loss: 0.3223\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3216 - val_loss: 0.3114\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3200 - val_loss: 0.5189\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3203 - val_loss: 0.4943\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3226 - val_loss: 0.4422\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3185 - val_loss: 0.3512\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3155 - val_loss: 0.3640\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3149 - val_loss: 0.3345\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3135 - val_loss: 0.3839\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3112 - val_loss: 0.3055\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3095 - val_loss: 0.3184\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3072 - val_loss: 0.3083\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3069 - val_loss: 0.3094\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3061 - val_loss: 0.2994\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3049 - val_loss: 0.3007\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3031 - val_loss: 0.3613\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3030 - val_loss: 0.3223\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3019 - val_loss: 0.4189\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3010 - val_loss: 0.2981\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2991 - val_loss: 0.4161\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.2989 - val_loss: 0.3032\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2977 - val_loss: 0.3653\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.2951 - val_loss: 0.3391\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.2944 - val_loss: 0.3360\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.2937 - val_loss: 0.3149\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2925 - val_loss: 0.2913\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 0.2914 - val_loss: 0.4095\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.2911 - val_loss: 0.2948\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.2904 - val_loss: 0.3080\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 86us/sample - loss: 0.2901 - val_loss: 0.2870\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 80us/sample - loss: 0.2880 - val_loss: 0.3050\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2881 - val_loss: 0.2925\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2867 - val_loss: 0.2906\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.2862 - val_loss: 0.3363\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2853 - val_loss: 0.3044\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.2859 - val_loss: 0.2903\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.2834 - val_loss: 0.3739\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.2828 - val_loss: 0.3077\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.2810 - val_loss: 0.3153\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.2841 - val_loss: 0.2847\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2819 - val_loss: 0.3556\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.2813 - val_loss: 0.2861\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2811 - val_loss: 0.3045\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.2774 - val_loss: 0.2848\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.2783 - val_loss: 0.4409\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2795 - val_loss: 1.3928\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.2963 - val_loss: 1.9865\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.2959 - val_loss: 0.3071\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2798 - val_loss: 0.3059\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.2789 - val_loss: 0.3217\n",
      "3870/3870 [==============================] - 0s 37us/sample - loss: 0.2939\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 235us/sample - loss: 1.4071 - val_loss: 4.1944\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.8157 - val_loss: 35.8347\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 1.1050 - val_loss: 166.4229\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 4.9353 - val_loss: 589.5366\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 8.3075 - val_loss: 2102.3293\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 54us/sample - loss: 26.7581 - val_loss: 8795.1571\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 77.6280 - val_loss: 33091.7189\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 485.4367 - val_loss: 130242.9571\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 857.3720 - val_loss: 497792.4372\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 5714.2303 - val_loss: 1922351.1303\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 51486.9040 - val_loss: 7528490.3691\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 19621.4950\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 245us/sample - loss: 1.3511 - val_loss: 8.3153\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5183 - val_loss: 15.8362\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 0.5111 - val_loss: 16.1180\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 0.5083 - val_loss: 17.7174\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5061 - val_loss: 18.6650\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5049 - val_loss: 20.7395\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.5016 - val_loss: 21.2555\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5038 - val_loss: 19.9381\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5021 - val_loss: 20.1074\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5037 - val_loss: 21.5393\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.5018 - val_loss: 22.4920\n",
      "3870/3870 [==============================] - 0s 32us/sample - loss: 1.0615\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 234us/sample - loss: 2.1333 - val_loss: 131.8225\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.2199 - val_loss: 267.1188\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 7.2360 - val_loss: 498.8157\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 2.8060 - val_loss: 836.8701\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 12.7016 - val_loss: 1752.4452\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 7.5845 - val_loss: 2871.8699\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 41.9221 - val_loss: 5375.2061\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 96.5209 - val_loss: 10101.7644\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 134.7231 - val_loss: 19333.1104\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 513.6542 - val_loss: 37487.8772\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 229.5914 - val_loss: 107739.7088\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 122.9122\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 307us/sample - loss: 0.7148 - val_loss: 1.3935\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4340 - val_loss: 1.8380\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4475 - val_loss: 0.4546\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4258 - val_loss: 0.9604\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3943 - val_loss: 0.6064\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3767 - val_loss: 0.7972\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3744 - val_loss: 0.7366\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3648 - val_loss: 0.4579\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3596 - val_loss: 0.3395\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3512 - val_loss: 0.3529\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3510 - val_loss: 0.3468\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3433 - val_loss: 0.3472\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3387 - val_loss: 0.3636\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3384 - val_loss: 0.3600\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3333 - val_loss: 0.3341\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3323 - val_loss: 0.3348\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3315 - val_loss: 0.3221\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3305 - val_loss: 0.3366\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3282 - val_loss: 0.3235\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3230 - val_loss: 0.3374\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3226 - val_loss: 0.3255\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.3218 - val_loss: 0.3093\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3198 - val_loss: 0.3296\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3178 - val_loss: 0.3339\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3175 - val_loss: 0.3118\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3142 - val_loss: 0.3630\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3137 - val_loss: 0.3213\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3129 - val_loss: 0.3208\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3112 - val_loss: 0.2991\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3081 - val_loss: 0.3189\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3095 - val_loss: 0.3024\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3070 - val_loss: 0.2945\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3063 - val_loss: 0.2923\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.3054 - val_loss: 0.3354\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3030 - val_loss: 0.2873\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3040 - val_loss: 0.2947\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3030 - val_loss: 0.3094\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3011 - val_loss: 0.2933\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.2981 - val_loss: 0.3305\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.2982 - val_loss: 0.3143\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.2968 - val_loss: 0.2982\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.2978 - val_loss: 0.2934\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.2951 - val_loss: 0.2951\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.2957 - val_loss: 0.2997\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.2950 - val_loss: 0.2955\n",
      "3870/3870 [==============================] - 0s 33us/sample - loss: 0.3342\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 320us/sample - loss: 0.7225 - val_loss: 0.4518\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4427 - val_loss: 0.4636\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4167 - val_loss: 0.3881\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4016 - val_loss: 0.4006\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3942 - val_loss: 0.4766\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3879 - val_loss: 0.4545\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3808 - val_loss: 0.3852\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3760 - val_loss: 0.3897\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3688 - val_loss: 0.7927\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3706 - val_loss: 0.5504\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3623 - val_loss: 0.3648\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3624 - val_loss: 0.3592\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3564 - val_loss: 0.4626\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3497 - val_loss: 0.8232\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3491 - val_loss: 0.3857\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3465 - val_loss: 0.8624\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3411 - val_loss: 0.4257\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3399 - val_loss: 0.5002\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3386 - val_loss: 0.4403\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3366 - val_loss: 0.8236\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3337 - val_loss: 0.5081\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3321 - val_loss: 0.5195\n",
      "3870/3870 [==============================] - 0s 36us/sample - loss: 0.3564\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 309us/sample - loss: 1.0184 - val_loss: 16.7859\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 87us/sample - loss: 0.8573 - val_loss: 0.9309\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.4359 - val_loss: 0.3866\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4027 - val_loss: 0.3826\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3879 - val_loss: 0.3568\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3766 - val_loss: 0.3557\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3692 - val_loss: 0.3598\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3656 - val_loss: 0.3734\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3625 - val_loss: 0.3379\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3601 - val_loss: 0.3325\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3571 - val_loss: 0.3593\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3574 - val_loss: 0.3397\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3545 - val_loss: 0.3501\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3523 - val_loss: 0.3297\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3512 - val_loss: 0.3795\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3482 - val_loss: 0.3348\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3465 - val_loss: 0.3344\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3452 - val_loss: 0.3528\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3438 - val_loss: 0.3207\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3439 - val_loss: 0.3264\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3431 - val_loss: 0.3170\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3383 - val_loss: 0.3384\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3369 - val_loss: 0.3695\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3362 - val_loss: 0.3289\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3347 - val_loss: 0.3217\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3335 - val_loss: 0.3271\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3307 - val_loss: 0.3331\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3301 - val_loss: 0.3130\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3300 - val_loss: 0.3178\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3280 - val_loss: 0.3072\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 75us/sample - loss: 0.3272 - val_loss: 0.3172\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3272 - val_loss: 0.3133\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3252 - val_loss: 0.3177\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3233 - val_loss: 0.3162\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3225 - val_loss: 0.3113\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3234 - val_loss: 0.3487\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3228 - val_loss: 0.3118\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3193 - val_loss: 0.3190\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3190 - val_loss: 0.3168\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3216 - val_loss: 0.3207\n",
      "3870/3870 [==============================] - 0s 37us/sample - loss: 0.3332\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 282us/sample - loss: 2.5058 - val_loss: 4.8093\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9756 - val_loss: 0.7868\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7642 - val_loss: 0.7075\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7158 - val_loss: 0.6972\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6864 - val_loss: 0.6473\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.6645 - val_loss: 0.6263\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6441 - val_loss: 0.6258\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6243 - val_loss: 0.5984\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.6084 - val_loss: 0.5979\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5901 - val_loss: 0.5632\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5759 - val_loss: 0.5439\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5608 - val_loss: 0.5307\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5475 - val_loss: 0.5201\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5356 - val_loss: 0.5309\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5235 - val_loss: 0.5068\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5124 - val_loss: 0.4848\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.5030 - val_loss: 0.4856\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4934 - val_loss: 0.4656\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4851 - val_loss: 0.4566\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4777 - val_loss: 0.4530\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4710 - val_loss: 0.4630\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4647 - val_loss: 0.4469\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4596 - val_loss: 0.4415\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4548 - val_loss: 0.4452\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4506 - val_loss: 0.4417\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4468 - val_loss: 0.4254\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4434 - val_loss: 0.4219\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4402 - val_loss: 0.4146\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4376 - val_loss: 0.4298\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4349 - val_loss: 0.4196\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4327 - val_loss: 0.4166\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4305 - val_loss: 0.4172\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4284 - val_loss: 0.4113\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4266 - val_loss: 0.4129\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4249 - val_loss: 0.4214\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4233 - val_loss: 0.4237\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4218 - val_loss: 0.4150\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4203 - val_loss: 0.4211\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4190 - val_loss: 0.3973\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4175 - val_loss: 0.4061\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4162 - val_loss: 0.4236\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.4151 - val_loss: 0.4121\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4138 - val_loss: 0.4232\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4129 - val_loss: 0.3989\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4116 - val_loss: 0.4161\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4106 - val_loss: 0.4119\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4095 - val_loss: 0.3982\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4084 - val_loss: 0.4167\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4075 - val_loss: 0.4263\n",
      "3870/3870 [==============================] - 0s 33us/sample - loss: 0.4208\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 286us/sample - loss: 2.0865 - val_loss: 1.5847\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.9267 - val_loss: 1.1020\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.7885 - val_loss: 1.2531\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.7339 - val_loss: 1.4465\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6970 - val_loss: 1.6194\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6674 - val_loss: 1.7997\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6421 - val_loss: 1.9843\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6197 - val_loss: 2.1898\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6001 - val_loss: 2.3183\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.5825 - val_loss: 2.4285\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5667 - val_loss: 2.4954\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5526 - val_loss: 2.4916\n",
      "3870/3870 [==============================] - 0s 33us/sample - loss: 0.6099\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 289us/sample - loss: 3.0177 - val_loss: 8.8867\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 1.1218 - val_loss: 0.9651\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.7599 - val_loss: 0.7425\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6916 - val_loss: 0.6684\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6616 - val_loss: 0.6501\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.6385 - val_loss: 0.6246\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6183 - val_loss: 0.5956\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.6004 - val_loss: 0.5782\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5833 - val_loss: 0.5610\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5684 - val_loss: 0.5477\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5542 - val_loss: 0.5370\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5408 - val_loss: 0.5169\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.5290 - val_loss: 0.5187\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.5177 - val_loss: 0.4950\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.5080 - val_loss: 0.5060\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4988 - val_loss: 0.4845\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4909 - val_loss: 0.4767\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4834 - val_loss: 0.4707\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4768 - val_loss: 0.4764\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4708 - val_loss: 0.4654\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4651 - val_loss: 0.4539\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4601 - val_loss: 0.4509\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4552 - val_loss: 0.4460\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4513 - val_loss: 0.4475\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4474 - val_loss: 0.4427\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4439 - val_loss: 0.4336\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4404 - val_loss: 0.4439\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4374 - val_loss: 0.4235\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4345 - val_loss: 0.4423\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4318 - val_loss: 0.4421\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4292 - val_loss: 0.4499\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4266 - val_loss: 0.4605\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4247 - val_loss: 0.4216\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4223 - val_loss: 0.4143\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4203 - val_loss: 0.4135\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4184 - val_loss: 0.4337\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4165 - val_loss: 0.4519\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4150 - val_loss: 0.4231\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 54us/sample - loss: 0.4133 - val_loss: 0.4149\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4116 - val_loss: 0.4254\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4103 - val_loss: 0.4394\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4090 - val_loss: 0.4151\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4076 - val_loss: 0.4324\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4064 - val_loss: 0.4278\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4052 - val_loss: 0.4080\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4040 - val_loss: 0.4033\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4029 - val_loss: 0.4244\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.4020 - val_loss: 0.4324\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4010 - val_loss: 0.4444\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4002 - val_loss: 0.3985\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3991 - val_loss: 0.4329\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3984 - val_loss: 0.4246\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3974 - val_loss: 0.4187\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3966 - val_loss: 0.4314\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3958 - val_loss: 0.4202\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3951 - val_loss: 0.3866\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3941 - val_loss: 0.4286\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3936 - val_loss: 0.4443\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3930 - val_loss: 0.3877\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3921 - val_loss: 0.4374\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3916 - val_loss: 0.3932\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3908 - val_loss: 0.4073\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3905 - val_loss: 0.3972\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3896 - val_loss: 0.3963\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3892 - val_loss: 0.3839\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3885 - val_loss: 0.4399\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3884 - val_loss: 0.3887\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3877 - val_loss: 0.4046\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3872 - val_loss: 0.3765\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3867 - val_loss: 0.4179\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3864 - val_loss: 0.3845\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3856 - val_loss: 0.4325\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3855 - val_loss: 0.3752\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3847 - val_loss: 0.4331\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3844 - val_loss: 0.4159\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3841 - val_loss: 0.4184\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 0.3834 - val_loss: 0.4425\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3832 - val_loss: 0.4292\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3827 - val_loss: 0.4351\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3823 - val_loss: 0.4452\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.3822 - val_loss: 0.3788\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3814 - val_loss: 0.4089\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3810 - val_loss: 0.3768\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 0.3821\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 3s 352us/sample - loss: 2.1305 - val_loss: 0.8287\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.7197 - val_loss: 0.7090\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.6324 - val_loss: 0.5809\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.5923 - val_loss: 0.5512\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.5613 - val_loss: 0.5821\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.5337 - val_loss: 0.4802\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 1s 83us/sample - loss: 0.5118 - val_loss: 0.4631\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.4942 - val_loss: 0.5087\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.4792 - val_loss: 0.4357\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4669 - val_loss: 0.4296\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.4563 - val_loss: 0.4182\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.4480 - val_loss: 0.4122\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 1s 70us/sample - loss: 0.4408 - val_loss: 0.4087\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.4346 - val_loss: 0.4068\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 1s 88us/sample - loss: 0.4293 - val_loss: 0.4010\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.4246 - val_loss: 0.3952\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 1s 89us/sample - loss: 0.4207 - val_loss: 0.3899\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4169 - val_loss: 0.3902\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 1s 121us/sample - loss: 0.4139 - val_loss: 0.3830\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4107 - val_loss: 0.3847\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4081 - val_loss: 0.3792\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.4054 - val_loss: 0.3780\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4029 - val_loss: 0.3743\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.4005 - val_loss: 0.3949\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3984 - val_loss: 0.3708\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3961 - val_loss: 0.3947\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3944 - val_loss: 0.3692\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3924 - val_loss: 0.3780\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3907 - val_loss: 0.3657\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3887 - val_loss: 0.3798\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3873 - val_loss: 0.3672\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3855 - val_loss: 0.3636\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3842 - val_loss: 0.3602\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3828 - val_loss: 0.3586\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3813 - val_loss: 0.3823\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3803 - val_loss: 0.3611\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3788 - val_loss: 0.3828\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3778 - val_loss: 0.3666\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3770 - val_loss: 0.3538\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3755 - val_loss: 0.3679\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3747 - val_loss: 0.3612\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3737 - val_loss: 0.3520\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3724 - val_loss: 0.3539\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3716 - val_loss: 0.3595\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3707 - val_loss: 0.3498\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3698 - val_loss: 0.3509\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3689 - val_loss: 0.3481\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 1s 82us/sample - loss: 0.3680 - val_loss: 0.3700\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 1s 74us/sample - loss: 0.3674 - val_loss: 0.3519\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 95us/sample - loss: 0.3665 - val_loss: 0.3458\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 1s 91us/sample - loss: 0.3654 - val_loss: 0.3802\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3653 - val_loss: 0.3447\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 1s 130us/sample - loss: 0.3642 - val_loss: 0.3744\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 1s 111us/sample - loss: 0.3639 - val_loss: 0.3444\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 1s 160us/sample - loss: 0.3630 - val_loss: 0.3444\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 1s 119us/sample - loss: 0.3620 - val_loss: 0.3874\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 1s 122us/sample - loss: 0.3619 - val_loss: 0.3429\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 1s 100us/sample - loss: 0.3610 - val_loss: 0.3773\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 1s 153us/sample - loss: 0.3608 - val_loss: 0.3457\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3598 - val_loss: 0.3416\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3593 - val_loss: 0.3464\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3589 - val_loss: 0.3399\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3580 - val_loss: 0.3467\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 1s 67us/sample - loss: 0.3577 - val_loss: 0.3395\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3572 - val_loss: 0.3427\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3568 - val_loss: 0.3382\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 1s 79us/sample - loss: 0.3560 - val_loss: 0.3702\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3558 - val_loss: 0.3380\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 1s 84us/sample - loss: 0.3552 - val_loss: 0.3369\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 1s 105us/sample - loss: 0.3547 - val_loss: 0.3374\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 1s 71us/sample - loss: 0.3541 - val_loss: 0.3365\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3536 - val_loss: 0.3596\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3532 - val_loss: 0.3367\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 65us/sample - loss: 0.3526 - val_loss: 0.3584\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3524 - val_loss: 0.3429\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3517 - val_loss: 0.3465\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3516 - val_loss: 0.3346\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3509 - val_loss: 0.3358\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3507 - val_loss: 0.3343\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 1s 76us/sample - loss: 0.3503 - val_loss: 0.3357\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 1s 90us/sample - loss: 0.3498 - val_loss: 0.3353\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 1s 184us/sample - loss: 0.3492 - val_loss: 0.3530\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 1s 175us/sample - loss: 0.3490 - val_loss: 0.3358\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 1s 181us/sample - loss: 0.3486 - val_loss: 0.3333\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 1s 192us/sample - loss: 0.3482 - val_loss: 0.3818\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 2s 207us/sample - loss: 0.3481 - val_loss: 0.3391\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 1s 164us/sample - loss: 0.3474 - val_loss: 0.3789\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 2s 210us/sample - loss: 0.3473 - val_loss: 0.3323\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 1s 155us/sample - loss: 0.3465 - val_loss: 0.3603\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 1s 177us/sample - loss: 0.3463 - val_loss: 0.3345\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 2s 253us/sample - loss: 0.3458 - val_loss: 0.3812\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 2s 222us/sample - loss: 0.3456 - val_loss: 0.3439\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 1s 149us/sample - loss: 0.3455 - val_loss: 0.3443\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 1s 77us/sample - loss: 0.3448 - val_loss: 0.3556\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.3447 - val_loss: 0.3308\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3442 - val_loss: 0.3937\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3441 - val_loss: 0.3350\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 1s 73us/sample - loss: 0.3431 - val_loss: 0.3307\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 0.3433 - val_loss: 0.3315\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3427 - val_loss: 0.3367\n",
      "3870/3870 [==============================] - 0s 34us/sample - loss: 0.3627\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 3s 324us/sample - loss: 1.9809 - val_loss: 24.4266\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.9334 - val_loss: 13.2001\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 1s 68us/sample - loss: 0.7919 - val_loss: 6.5516\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.7195 - val_loss: 3.0275\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.6646 - val_loss: 1.1808\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6195 - val_loss: 0.6208\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.5824 - val_loss: 0.5877\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.5515 - val_loss: 0.8282\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.5272 - val_loss: 1.1287\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5074 - val_loss: 1.4133\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4917 - val_loss: 1.5554\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4791 - val_loss: 1.8483\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4687 - val_loss: 1.8819\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4600 - val_loss: 1.9322\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4525 - val_loss: 1.8450\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4461 - val_loss: 1.8840\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4408 - val_loss: 1.7507\n",
      "3870/3870 [==============================] - 0s 31us/sample - loss: 0.4937\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 2s 316us/sample - loss: 2.0434 - val_loss: 2.2221\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.7460 - val_loss: 0.6795\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.6562 - val_loss: 0.6790\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.6165 - val_loss: 0.6086\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5879 - val_loss: 0.5580\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5611 - val_loss: 0.5218\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.5396 - val_loss: 0.5113\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5212 - val_loss: 0.4843\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.5059 - val_loss: 0.4757\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4923 - val_loss: 0.4666\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4813 - val_loss: 0.4519\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4715 - val_loss: 0.4477\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4630 - val_loss: 0.4327\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4558 - val_loss: 0.4224\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4496 - val_loss: 0.4456\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4439 - val_loss: 0.4127\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4391 - val_loss: 0.4122\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.4346 - val_loss: 0.4031\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4303 - val_loss: 0.4309\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.4268 - val_loss: 0.4112\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.4236 - val_loss: 0.3936\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.4201 - val_loss: 0.4153\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4177 - val_loss: 0.3870\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 1s 81us/sample - loss: 0.4153 - val_loss: 0.3903\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 1s 92us/sample - loss: 0.4130 - val_loss: 0.4012\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4104 - val_loss: 0.4038\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.4084 - val_loss: 0.3879\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 1s 72us/sample - loss: 0.4062 - val_loss: 0.4345\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4052 - val_loss: 0.3756\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4029 - val_loss: 0.3854\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.4010 - val_loss: 0.4446\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.4004 - val_loss: 0.3713\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3980 - val_loss: 0.3823\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3968 - val_loss: 0.3701\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3953 - val_loss: 0.3669\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3941 - val_loss: 0.3681\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3925 - val_loss: 0.4426\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 62us/sample - loss: 0.3918 - val_loss: 0.4028\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3908 - val_loss: 0.3651\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 1s 65us/sample - loss: 0.3895 - val_loss: 0.3619\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3881 - val_loss: 0.3819\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 60us/sample - loss: 0.3871 - val_loss: 0.4170\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3863 - val_loss: 0.3645\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 61us/sample - loss: 0.3851 - val_loss: 0.3907\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3842 - val_loss: 0.3915\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3833 - val_loss: 0.3775\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 1s 66us/sample - loss: 0.3825 - val_loss: 0.3577\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 0.3810 - val_loss: 0.4121\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 59us/sample - loss: 0.3808 - val_loss: 0.3613\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3797 - val_loss: 0.3785\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3793 - val_loss: 0.3621\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 1s 69us/sample - loss: 0.3778 - val_loss: 0.4191\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 57us/sample - loss: 0.3780 - val_loss: 0.3583\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3767 - val_loss: 0.3588\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 55us/sample - loss: 0.3755 - val_loss: 0.4120\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3757 - val_loss: 0.3585\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 58us/sample - loss: 0.3745 - val_loss: 0.3742\n",
      "3870/3870 [==============================] - 0s 29us/sample - loss: 0.3748\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 3s 286us/sample - loss: 0.8702 - val_loss: 0.9153\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.5145 - val_loss: 2.1291\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 0.4530 - val_loss: 2.2334\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.4223 - val_loss: 0.9570\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 99us/sample - loss: 0.3927 - val_loss: 0.3736\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 0.3762 - val_loss: 0.3899\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 100us/sample - loss: 0.3663 - val_loss: 0.5179\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 0.3603 - val_loss: 0.3378\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 100us/sample - loss: 0.3522 - val_loss: 0.3639\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.3468 - val_loss: 0.3244\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.3408 - val_loss: 0.3273\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.3357 - val_loss: 0.5193\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 93us/sample - loss: 0.3331 - val_loss: 0.3277\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.3299 - val_loss: 0.4016\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.3252 - val_loss: 0.3317\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 100us/sample - loss: 0.3217 - val_loss: 0.3222\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.3190 - val_loss: 0.4243\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 94us/sample - loss: 0.3164 - val_loss: 0.3095\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.3140 - val_loss: 0.4109\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 1s 99us/sample - loss: 0.3119 - val_loss: 0.3111\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 1s 101us/sample - loss: 0.3100 - val_loss: 0.4131\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 1s 101us/sample - loss: 0.3078 - val_loss: 0.3137\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 1s 101us/sample - loss: 0.3046 - val_loss: 0.3291\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 1s 103us/sample - loss: 0.3034 - val_loss: 0.3047\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 1s 104us/sample - loss: 0.3018 - val_loss: 0.3848\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 1s 105us/sample - loss: 0.3006 - val_loss: 0.2923\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.2984 - val_loss: 0.4533\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.2980 - val_loss: 0.2901\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 1s 101us/sample - loss: 0.2946 - val_loss: 0.3002\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 0.2941 - val_loss: 0.2899\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 1s 100us/sample - loss: 0.2927 - val_loss: 0.4471\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 0.2913 - val_loss: 0.2911\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.2900 - val_loss: 0.3538\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 1s 100us/sample - loss: 0.2883 - val_loss: 0.2830\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 1s 103us/sample - loss: 0.2877 - val_loss: 0.4005\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.2874 - val_loss: 0.3452\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 1s 101us/sample - loss: 0.2868 - val_loss: 0.4757\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 1s 104us/sample - loss: 0.2861 - val_loss: 0.3365\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 1s 103us/sample - loss: 0.2846 - val_loss: 0.4386\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 1s 110us/sample - loss: 0.2847 - val_loss: 0.3030\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 1s 108us/sample - loss: 0.2824 - val_loss: 0.6062\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 1s 99us/sample - loss: 0.2825 - val_loss: 0.3136\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.2813 - val_loss: 0.4963\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.2813 - val_loss: 0.3134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x00000228D3371E48>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000228D5609978>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7...\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_iter = nb de test des combinaisons de parametres\n",
    "# validationset used only for early stopping, randomizedSearchCV uses already CV for validation\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg,param_distribs,n_iter=10,cv=3)\n",
    "rnd_search_cv.fit(X_train,y_train,epochs=100,\n",
    "             validation_data = (X_valid,y_valid), \n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.003867813551051595, 'n_hidden': 3, 'n_neurons': 66}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
